<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>(p)retired</title>
    <link>https://pretired.dazwilkin.com/</link>
    <description>Recent content on (p)retired</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Oct 2023 00:00:00 -0700</lastBuildDate><atom:link href="https://pretired.dazwilkin.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prometheus Operator support an auth proxy for Service Discovery</title>
      <link>https://pretired.dazwilkin.com/posts/231017/</link>
      <pubDate>Tue, 17 Oct 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/231017/</guid>
      <description>For ackalctld to be deployable to Kubernetes with Prometheus Operator, it is necessary to Enable ScrapeConfig to use (discovery|target) proxies #5966. While I&amp;rsquo;m familiar with Kubernetes, Kubernetes operators (Ackal uses one built with the Operator SDK) and Prometheus Operator, I&amp;rsquo;m unfamiliar with developing Prometheus Operator. This (and subsequent) posts will document some preliminary work on this.
Cloned Prometheus Operator
Branched scrape-config-url-proxy
I&amp;rsquo;m unsure how to effect these changes and unsure whether documentation exists.</description>
    </item>
    
    <item>
      <title>Prometheus Operator `ScrapeConfig`</title>
      <link>https://pretired.dazwilkin.com/posts/231013/</link>
      <pubDate>Fri, 13 Oct 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/231013/</guid>
      <description>TL;DR Enable ScrapeConfig to use (discovery|target) proxies
I&amp;rsquo;ve developed a companion, local daemon (called ackalctld) for Ackal that provides a functionally close version of the service.
One way to deploy ackalctld is to use Kubernetes and it would be convenient if the Prometheus metrics were scrapeable by Prometheus Operator.
In order for this to work, Prometheus Operator needs to be able to scrape Google Cloud Run targets because ackalctld creates Cloud Run services for its health check clients.</description>
    </item>
    
    <item>
      <title>Prometheus Exporter for Koyeb</title>
      <link>https://pretired.dazwilkin.com/posts/230709/</link>
      <pubDate>Sun, 09 Jul 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230709/</guid>
      <description>Yet another cloud platform exporter for resource|cost management. This time for Koyeb with Koyeb Exporter.
Deploying resources to cloud platforms generally incurs cost based on the number of resources deployed, the time each resource is deployed and the cost (per period of time) that the resource is deployed. It is useful to be able to automatically measure and alert on all the resources deployed on all the platforms that you&amp;rsquo;re using and this is an intent of these exporters.</description>
    </item>
    
    <item>
      <title>Kubernetes Python SDK w/ CRDs</title>
      <link>https://pretired.dazwilkin.com/posts/230708/</link>
      <pubDate>Sat, 08 Jul 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230708/</guid>
      <description>Responded to Get Custom K8s Resource using Python and found the CustomObjectsApi documentation unclear.
If you have a cluster and a kubeconfig file with a correctly configured current-context, so that you can successfully:
PLURAL=&amp;#34;checks&amp;#34; kubectl get ${PLURAL} \ --all-namespaces NOTE I&amp;rsquo;m using Ackal&amp;rsquo;s CRDs in these examples.
Then you can use the following code to access the cluster&amp;rsquo;s REST API server to enumerate its CRDs:
main.py:
from __future__ import print_function from kubernetes import client, config from kubernetes.</description>
    </item>
    
    <item>
      <title>GoatCounter with Hugo with Ananke</title>
      <link>https://pretired.dazwilkin.com/posts/230622/</link>
      <pubDate>Thu, 22 Jun 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230622/</guid>
      <description>Thanks to Joe Mooring for his solution to my question as to how to do this.
I&amp;rsquo;ve decided to ditch Google Analytics and am evaluating using GoatCounter with Hugo with Ananke theme.
This was the layout of the site:
. ├── archetypes ├── content │ └── posts ├── go.mod ├── go.sum ├── hugo.toml ├── layouts ├── public └── static This is the structure (of layouts) with the necessary changes:
. ├── archetypes ├── content │ └── posts ├── go.</description>
    </item>
    
    <item>
      <title>Python Protobuf changes</title>
      <link>https://pretired.dazwilkin.com/posts/230607/</link>
      <pubDate>Wed, 07 Jun 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230607/</guid>
      <description>Python&amp;rsquo;s Protocol Buffers code-generation using protoc has had significant changes that can cause developers&amp;hellip; &amp;ldquo;challenges&amp;rdquo;. This post summarizes my experience of these mostly to save me from repreatedly recreating this history for myself when I forget it.
Version change Generated code change Implementation Backends I&amp;rsquo;ll use this summarized table of proto and the Pypi library&amp;rsquo;s history in this post. protoc refers to the compiler that supports code-generation in multiple languages. protobuf refers to the corresponding Python (runtime) library on Pypi:</description>
    </item>
    
    <item>
      <title>Routing Firestore events to GKE with Eventarc</title>
      <link>https://pretired.dazwilkin.com/posts/230530/</link>
      <pubDate>Tue, 30 May 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230530/</guid>
      <description>Google announced Firestore &amp;hellip; integration with Eventarc. Ackal uses Firestore to persist Customer and Check information and it uses Google Cloud Firestore Triggers to handle events on these document types.
Eventarc feels like the strategic future of eventing in Google Cloud and I&amp;rsquo;ve been concerned since adopting the technology that Google would abandon Google Cloud Firestore Triggers.
For this reason, when I saw last week&amp;rsquo;s announcement, I thought I should evaluate the mechanism and this blog post is a summary of that work.</description>
    </item>
    
    <item>
      <title>Deploying Hugo site to DigitalOcean Apps</title>
      <link>https://pretired.dazwilkin.com/posts/230502/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230502/</guid>
      <description>I&amp;rsquo;ve been running a DigitalOcean Apps static site for Hugo using the Hugo Buildpack.
I&amp;rsquo;ve migrated a set of Hugo sites to use Hugo Modules which includes the addition of go.mod (and go.sum) files to the Hugo project in order to manage e.g. themes.
Unfortunately, the Hugo Buildpack used by DigitalOcean Apps does not support Hugo Modules. DigitalOcean support recommended that I switch to use a build with a Dockerfile. Unfortunately (!</description>
    </item>
    
    <item>
      <title>Robusta KRR w/ GMP</title>
      <link>https://pretired.dazwilkin.com/posts/230427/</link>
      <pubDate>Thu, 27 Apr 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230427/</guid>
      <description>I&amp;rsquo;ve been spending time recently optimizing Ackal&amp;rsquo;s use of Google Cloud Logging and Cloud Monitoring in posts:
Filtering metrics w/ Google Managed Prometheus Kubernetes metrics, metrics everywhere Google Metric Diagnostics and Metric Data Ingested Yesterday, I read that Robusta has a new open source project Kubernetes Resource Recommendations (KRR) so I took some time to evaluate it.
This post describes the changes I had to make to get KRR working with Google Managed Prometheus (GMP):</description>
    </item>
    
    <item>
      <title>Google Metric Diagnostics and Metric Data Ingested</title>
      <link>https://pretired.dazwilkin.com/posts/230425/</link>
      <pubDate>Tue, 25 Apr 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230425/</guid>
      <description>I&amp;rsquo;ve been on an efficiency drive with Cloud Logging and Cloud Monitoring.
With regards Cloud Logging, I&amp;rsquo;m contemplating (!) eliminating almost all log storage. As it is I&amp;rsquo;ve buzz cut log storage with a _Default sink that has comprehensive sets of NOT LOG_ID(X) inclusion and exclusion filters. As I was doing so, I began to wonder why I need to pay for the storage of much logging. There&amp;rsquo;s the comfort from knowing that everything you may ever need is being logged (at least for 30 days) but there&amp;rsquo;s also the costs that that entails.</description>
    </item>
    
    <item>
      <title>Prometheus Exporter for Azure (Container Apps)</title>
      <link>https://pretired.dazwilkin.com/posts/230420/</link>
      <pubDate>Thu, 20 Apr 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230420/</guid>
      <description>I&amp;rsquo;ve written Prometheus Exporters for various cloud platforms. My motivation for writing these Exporters is that I want a unified mechanism to track my usage of these platform&amp;rsquo;s services. It&amp;rsquo;s easy to deploy a service on a platform and inadvertently leave it running (up a bill). The set of exporters is:
Prometheus Exporter for Azure Prometheus Exporter for Fly.io Prometheus Exporter for GCP Prometheus Exporter for Linode Prometheus Exporter for Vultr This post describes the recently-added Azure Exporter which only provides metrics for Container Apps and Resource Groups.</description>
    </item>
    
    <item>
      <title>Kubernetes metrics, metrics everywhere</title>
      <link>https://pretired.dazwilkin.com/posts/230419/</link>
      <pubDate>Wed, 19 Apr 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230419/</guid>
      <description>I&amp;rsquo;ve been tinkering with ways to &amp;ldquo;unit-test&amp;rdquo; my assumptions when using cloud platforms. I recently wrote about good posts by Google describing achieving cost savings with Cloud Monitoring and Cloud Logging:
How to identify and reduce costs of your Google Cloud observability in Cloud Monitoring Cloud Logging pricing for Cloud Admins: How to approach it &amp;amp; save cost With Cloud Monitoring, I&amp;rsquo;ve restricted the prometheus.googleapis.com metrics that are being ingested but realized I wanted to track the number of Pods (and Containers) deployed to a GKE cluster.</description>
    </item>
    
    <item>
      <title>Filtering metrics w/ Google Managed Prometheus</title>
      <link>https://pretired.dazwilkin.com/posts/230413/</link>
      <pubDate>Thu, 13 Apr 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230413/</guid>
      <description>Google has published two, very good blog posts on cost management:
How to identify and reduce costs of your Google Cloud observability in Cloud Monitoring Cloud Logging pricing for Cloud Admins: How to approach it &amp;amp; save cost This post is about my application cost reductions for Cloud Monitoring for Ackal.
I&amp;rsquo;m pleased with Google Cloud Managed Service for Prometheus (hereinafter GMP). I&amp;rsquo;ve a strong preference for letting service providers run components of Ackal that I consider important but non-differentiating.</description>
    </item>
    
    <item>
      <title>Azure Container Apps</title>
      <link>https://pretired.dazwilkin.com/posts/230404/</link>
      <pubDate>Tue, 04 Apr 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230404/</guid>
      <description>The majority of Ackal&amp;rsquo;s components are deployed to Google Cloud. However, by its nature, Ackal benefits from deployments that span cloud platforms. I&amp;rsquo;ve deployed Ackal&amp;rsquo;s gRPC health checks to Fly, and managed Kubernetes services on Linode and Vultr.
Today, I decided to revisit¹ Azure. Ackal uses Azure (Active Directory) for one of its OAuth providers. This time, I wanted to deploy a containerized gRPC service. Azure provides several container-oriented services. I decided to use Azure Container Apps and, in hindsight, find it analogous to Google Cloud Run.</description>
    </item>
    
    <item>
      <title>Apps Script connecting to GCS</title>
      <link>https://pretired.dazwilkin.com/posts/230329/</link>
      <pubDate>Wed, 29 Mar 2023 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230329/</guid>
      <description>I&amp;rsquo;m building a Google Sheet that interacts with Google Cloud Storage (GCS) objects using Apps Script.
I Googled but found few examples of such integrations beyond out-of-band solutions (e.g. Python solutions) that interact with Google services and program Google Sheets using its library.
In my case, I&amp;rsquo;m going to bind a Google Sheet to a specific Google Cloud project and my Google (User) account has owner access to the Google Cloud Storage bucket and its objects.</description>
    </item>
    
    <item>
      <title>Access Google Services using gRPC</title>
      <link>https://pretired.dazwilkin.com/posts/230314/</link>
      <pubDate>Tue, 14 Mar 2023 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230314/</guid>
      <description>Google publishes interface definitions of Google APIs (services) that support REST and gRPC in a repo called Google APIs. Google&amp;rsquo;s SDKs uses gRPC to access these services but, how to do this using e.g. gRPCurl?
I wanted to debug Cloud Profiler and its agent makes UpdateProfile RPCs to cloudprofiler.googleapis.com. Cloud Profiler is more challenging service to debug because (a) it&amp;rsquo;s publicly &amp;ldquo;write-only&amp;rdquo;; and (b) it has complex messages. UpdateProfile sends UpdateProfileRequest messages that include Profile messages that include profile_bytes which are gzip compressed serialized protos of pprof&amp;rsquo;s Profile.</description>
    </item>
    
    <item>
      <title>Kubernetes Operators</title>
      <link>https://pretired.dazwilkin.com/posts/230310/</link>
      <pubDate>Fri, 10 Mar 2023 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230310/</guid>
      <description>Ackal uses a Kubernetes Operator to orchestrate the lifecycle of its health checks. Ackal&amp;rsquo;s Operator is written in Go using kubebuilder.
Yesterday, my interest was piqued by a MetalBear blog post Writing a Kubernetes Operator [in Rust]. I spent some time reimplementing one of Ackal&amp;rsquo;s CRDs (Check) using kube-rs and not only refreshed my Rust knowledge but learned a bunch more about Kubernetes and Operators.
While rummaging around the Kubernetes documentation, I discovered flant&amp;rsquo;s Shell-operator and spent some time today exploring its potential.</description>
    </item>
    
    <item>
      <title>Secure (TLS) gRPC services with LKE</title>
      <link>https://pretired.dazwilkin.com/posts/230215/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230215/</guid>
      <description>NOTE cert-manager is a better solution to what follows.
I wrote about deploying Secure (TLS) gRPC services with Vultr Kubernetes Engine (VKE). This week, I&amp;rsquo;ve reproduced this deployment using Linode Kubernetes Engine (LKE).
Thanks to the consistency provided by Kubernetes, the Kubernetes programming is almost identical. The main differences are between the CLI&amp;rsquo;s provided by these platforms. Both are good. They&amp;rsquo;re just different.
I&amp;rsquo;m going to include the linode-cli commands I&amp;rsquo;m using in this post as I found it slightly more quirky.</description>
    </item>
    
    <item>
      <title>Authenticate PromLens to Google Managed Prometheus</title>
      <link>https://pretired.dazwilkin.com/posts/230104/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/230104/</guid>
      <description>I&amp;rsquo;m using Google Managed Service for Prometheus (GMP) and liking it.
Sometime ago, I tried using PromLens with GMP but GMP&amp;rsquo;s Prometheus HTTP API endpoint requires auth and I&amp;rsquo;ve battled Prometheus&amp;rsquo; somewhat limited auth mechanism before (Scraping metrics exposed by Google Cloud Run services that require authentication).
Listening to PromCon EU 2022 videos, I learned that PromLens has been open sourced and contributed to the Prometheus project. Eventually, the functionality of PromLens should be combined into the Prometheus UI.</description>
    </item>
    
    <item>
      <title>Maintaining Container Images</title>
      <link>https://pretired.dazwilkin.com/posts/221128/</link>
      <pubDate>Mon, 28 Nov 2022 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/221128/</guid>
      <description>As I contemplate moving my &amp;ldquo;thing&amp;rdquo; into production, I&amp;rsquo;m anticipating aspects of the application that need maintenance and how this can be automated.
I&amp;rsquo;d been negligent in the maintenance of some of my container images.
I&amp;rsquo;m using mostly Go and some Rust as the basis of static(ally-compiled) binaries that run in these containers but not every container has a base image of scratch. scratch is the only base image that doesn&amp;rsquo;t change and thus the only base image that doesn&amp;rsquo;t require that container images buit FROM it, be maintained.</description>
    </item>
    
    <item>
      <title>Delegate domain-wide authority using Golang</title>
      <link>https://pretired.dazwilkin.com/posts/221117/</link>
      <pubDate>Thu, 17 Nov 2022 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/221117/</guid>
      <description>I&amp;rsquo;d not used Google&amp;rsquo;s Domain-wide Delegation from Golang and struggled to find example code.
Google provides Java and Python samples.
Google has a myriad packages implementing its OAuth security and it&amp;rsquo;s always daunting trying to determine which one to use.
As it happens, I backed into the solution through client.Options
ctx := context.Background() // Google Workspace APIS don&amp;#39;t use IAM do use OAuth scopes // Scopes used here must be reflected in the scopes on the // Google Workspace Domain-wide Delegate client scopes := []string{ .</description>
    </item>
    
    <item>
      <title>`curl`&#39;ing a Tailscale Webhook</title>
      <link>https://pretired.dazwilkin.com/posts/221114/</link>
      <pubDate>Mon, 14 Nov 2022 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/221114/</guid>
      <description>[Tailscale] is really good. I&amp;rsquo;ve been using it as a virtual private network to span 2 home networks and to securely (!) access my hosts when I&amp;rsquo;m remote.
Recently Tailscale added Webhook functionality to permit processing subscribed-to (Tailscale) events. I&amp;rsquo;m always a sucker for a webhook ;-)
Here&amp;rsquo;s a curl command to send a test event to a Tailscale Webhook:
URL=&amp;#34;&amp;#34; # From Tailscale&amp;#39;s docs # https://tailscale.com/kb/1213/webhooks/#events-payload BODY=&amp;#39; [ { &amp;#34;timestamp&amp;#34;: &amp;#34;2022-09-21T13:37:51.</description>
    </item>
    
    <item>
      <title>The curious cases of the `deleted:serviceaccount`</title>
      <link>https://pretired.dazwilkin.com/posts/221111/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/221111/</guid>
      <description>While testing Firestore export and import yesterday and checking the IAM permissions on a Cloud Storage Bucket, I noticed some Member (member) values (I think Google refers to these as Principals) were logical but unfamiliar to me:
deleted:serviceAccount:{email}?uid={uid} I was using gsutil iam get gs://${BUCKET} because I&amp;rsquo;d realized (and this is another useful lesson) that, as I&amp;rsquo;ve been creating daily test projects, I&amp;rsquo;ve been binding each project&amp;rsquo;s Firestore Service Account (service-{project-number}@gcp-sa-firestore.</description>
    </item>
    
    <item>
      <title>Firestore Export &amp; Import</title>
      <link>https://pretired.dazwilkin.com/posts/221110/</link>
      <pubDate>Thu, 10 Nov 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/221110/</guid>
      <description>I&amp;rsquo;m using Firestore to maintain state in my &amp;ldquo;thing&amp;rdquo;.
In an attempt to ensure that I&amp;rsquo;m able to restore the database, I run (Cloud Scheduler) scheduled backups (see Automating Scheduled Firestore Exports and I&amp;rsquo;ve been testing imports to ensure that the process works.
It does.
I thought I&amp;rsquo;d document an important but subtle consideration with Firestore exports (which I&amp;rsquo;d not initially understood).
Google facilitates that backup process with the sibling commands:</description>
    </item>
    
    <item>
      <title>Basic programmatic access to GitHub Issues</title>
      <link>https://pretired.dazwilkin.com/posts/221106/</link>
      <pubDate>Sun, 06 Nov 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/221106/</guid>
      <description>It&amp;rsquo;s been a while!
I&amp;rsquo;ve been spending time writing Bash scripts and a web site but neither has been sufficiently creative that I&amp;rsquo;ve felt worth a blog post.
As I&amp;rsquo;ve been finalizing the web site, I needed an Issue Tracker and decided to leverage GitHub(&amp;rsquo;s Issues).
As a former Googler, I&amp;rsquo;m familiar with Google&amp;rsquo;s (excellent) internal issue tracking tool (Buganizer) and it&amp;rsquo;s public manifestation Issue Tracker. Google documents Issue Tracker and its Issue type which I&amp;rsquo;ve mercilessly plagiarized in my implementation.</description>
    </item>
    
    <item>
      <title>Secure (TLS) gRPC services with VKE</title>
      <link>https://pretired.dazwilkin.com/posts/220603/</link>
      <pubDate>Fri, 03 Jun 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220603/</guid>
      <description>NOTE cert-manager is a better solution to what follows.
I&amp;rsquo;ve a need to deploy a Vultr Kubernetes Engine (VKE) cluster on a daily basis (create and delete within a few hours) and expose (securely|TLS) a gRPC service.
I have an existing solution Automatic Certs w/ Golang gRPC service on Compute Engine that combines a gRPC Healthchecking and an ACME service and decided to reuse this.
In order for it work, we need:</description>
    </item>
    
    <item>
      <title>Vultr CLI and JSON output</title>
      <link>https://pretired.dazwilkin.com/posts/220602/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220602/</guid>
      <description>I&amp;rsquo;ve begun exploring Vultr after the company announced a managed Kubernetes offering Vultr Kubernetes Engine (VKE).
In my brief experience, it&amp;rsquo;s a decent platform and its CLI vultr-cli is mostly (!) good. The CLI has a limitation in that command output is text formatted and this makes it challenging to parse the output when scripting.
NOTE The Vultr developers have a branch rewrite that includes a solution to this problem.</description>
    </item>
    
    <item>
      <title>Automating HackMD documents</title>
      <link>https://pretired.dazwilkin.com/posts/220524/</link>
      <pubDate>Tue, 24 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220524/</guid>
      <description>I was introduced to HackMD while working on an open-source project. It&amp;rsquo;s a collaborative editing tool for Markdown documents and there&amp;rsquo;s an API
I wanted to be able to programmatically edit one of my documents with a daily update. The API is easy-to-use and my only challenge was futzing with escape characters in bash strips representing the document Markdown content.
You&amp;rsquo;ll need an account with HackMD and an to Create API Token that I&amp;rsquo;ll refer to as TOKEN.</description>
    </item>
    
    <item>
      <title>Prometheus Exporters for fly.io and Vultr</title>
      <link>https://pretired.dazwilkin.com/posts/220520/</link>
      <pubDate>Fri, 20 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220520/</guid>
      <description>I&amp;rsquo;ve been on a roll building utilities this week. I developed a Service Health dashboard for my &amp;ldquo;thing&amp;rdquo;, a Prometheus Exporter for Fly.io and today, a Prometheus Exporter for Vultr. This is motivated by the fear that I will forget a deployed Cloud resource and incur a horrible bill.
I&amp;rsquo;ve no written several Prometheus Exporters for cloud platforms:
Prometheus Exporter for GCP Prometheus Exporter for Linode Prometheus Exporter for Fly.io Prometheus Exporter for Vultr Each of them monitors resource deployments and produces resource count metrics that can be scraped by Prometheus and alerted with Alertmanager.</description>
    </item>
    
    <item>
      <title>Using Google Monitoring Alerting to send Pushover notifications</title>
      <link>https://pretired.dazwilkin.com/posts/220514/</link>
      <pubDate>Sat, 14 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220514/</guid>
      <description>Table of Contents Artifacts Pushover Caveat Cloud Monitoring Webhook Cloud Functions Cloud Run Artifacts GitHub: go-gcp-pushover-notificationchannel Image: ghcr.io/dazwilkin/go-gcp-pushover-notificationchannel:220515 Pushover Logging in to your Pushover account, you will be presented with a summary|dashboard page that includes Your User Key. Copy the value of this key into a variable called PUSHOVER_USER
Create New Application|API Token
Pushover API has a Pushing Messages method. The documentation describes the format of the HTTP Request. It must be a POST using TLS (https://) to https://api.</description>
    </item>
    
    <item>
      <title>Cloud Run custom domain mappings</title>
      <link>https://pretired.dazwilkin.com/posts/220506/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220506/</guid>
      <description>I have several Cloud Run services that I want to map to a domain.
During development, I create a Google Cloud Platform (GCP) project each day into which everything is deployed. This means that, every day, the Cloud Run services have newly non-inferable (to me) URLs. I thought this would be tedious to manage because:
My DNS service isn&amp;rsquo;t programmable (I know!) Cloud Run services have non-inferable (by me) URLs i.</description>
    </item>
    
    <item>
      <title>Automating Scheduled Firestore Exports</title>
      <link>https://pretired.dazwilkin.com/posts/220503/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220503/</guid>
      <description>For my &amp;ldquo;thing&amp;rdquo;, I use Firestore to persist state. I like Firestore a lot and, having been around Google for almost (!) a decade, I much prefer it to Datastore.
Firestore has a managed export|import service and I use this to backup Firestore collections|documents.
I&amp;rsquo;d been doing backups manually (using gcloud) and decided today to take the plunge and use Cloud Scheduler for the first time. I&amp;rsquo;d been reluctant to do this until now because I&amp;rsquo;d assumed incorrectly that I&amp;rsquo;d need to write a wrapping service to invoke the export.</description>
    </item>
    
    <item>
      <title>Playing with GitHub Container Registry REST API</title>
      <link>https://pretired.dazwilkin.com/posts/220422/</link>
      <pubDate>Fri, 22 Apr 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220422/</guid>
      <description>I&amp;rsquo;ve a day to catch up on blogging. I&amp;rsquo;m building a &amp;ldquo;thing&amp;rdquo; and getting this near to the finish line consumes my time and has meant that I&amp;rsquo;m not originating anything particularly new. However, there are a couple of tricks in my deployment process that may be of interest to others.
I&amp;rsquo;ve been a long-term using of Google&amp;rsquo;s [Cloud Build] and like the simplicity (everything&amp;rsquo;s a container, alot!). Because I&amp;rsquo;m using GitHub repos, I&amp;rsquo;ve been using GitHub Actions to (re)build containers on pushes and GitHub Container registry (GHCR) to store the results.</description>
    </item>
    
    <item>
      <title>Using Google&#39;s Public Certificate Authority with Golang autocert</title>
      <link>https://pretired.dazwilkin.com/posts/220421/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220421/</guid>
      <description>Last year, I wrote about using Automatic Certs w/ Golang gRPC service on Compute Engine. That solution uses ACME with (the wonderful) Let&amp;rsquo;s Encrypt. Google is offering a private preview of Automate Public Certificates Lifecycle Management via RFC 8555 (ACME) and, because I&amp;rsquo;m using Google Cloud Platform extensively to build a &amp;ldquo;thing&amp;rdquo; and I think it would be useful to have a backup to Let&amp;rsquo;s Encrypt, I thought I&amp;rsquo;d give the solution a try.</description>
    </item>
    
    <item>
      <title>Prometheus HTTP Service Discovery of Cloud Run services</title>
      <link>https://pretired.dazwilkin.com/posts/220225/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220225/</guid>
      <description>Some time ago, I wrote about using Prometheus Service Discovery w/ Consul for Cloud Run and also Scraping metrics exposed by Google Cloud Run services that require authentication. Both solutions remain viable but they didn&amp;rsquo;t address another use case for Prometheus and Cloud Run services that I have with a &amp;ldquo;thing&amp;rdquo; that I&amp;rsquo;ve been building.
In this scenario, I want to:
Configure Prometheus to scrape Cloud Run service metrics Discover Cloud Run services dynamically Authenticate to Cloud Run using Firebase Auth ID tokens These requirements and &amp;ndash; one other &amp;ndash; present several challenges:</description>
    </item>
    
    <item>
      <title>Automatic Certs w/ Golang gRPC service on Compute Engine</title>
      <link>https://pretired.dazwilkin.com/posts/211130/</link>
      <pubDate>Tue, 30 Nov 2021 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211130/</guid>
      <description>I needed to deploy a healthcheck-enabled gRPC TLS-enabled service. Fortunately, most (all?) of the SDKs include an implementation, e.g. Golang has grpc-go/health.
I learned in my travels that:
DigitalOcean [App] platform does not (link) work with TLS-based gRPC apps. Fly has a regression (link) that breaks gRPC So, I resorted to Google Cloud Platform (GCP). Although Cloud Run would be well-suited to running the gRPC app, it uses a proxy|sidecar to provision a cert for the app and I wanted to be able to (easily use a custom domain) and give myself a somewhat general-purpose solution.</description>
    </item>
    
    <item>
      <title>Firebase Auth authorized domains</title>
      <link>https://pretired.dazwilkin.com/posts/211026/</link>
      <pubDate>Tue, 26 Oct 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211026/</guid>
      <description>I&amp;rsquo;m using Firebase Authentication in a project to authenticate users of various OAuth2 identity systems. Firebase Authentication requires a set of Authorized Domains.
The (web) app that interacts with Firebase Authentication is deployed to Cloud Run. The Authorized Domains list must include the app&amp;rsquo;s Cloud Run service URL.
Cloud Run service URLs vary by Project (ID). They are a combination of the service name, a hash (?) of the Project (ID) and .</description>
    </item>
    
    <item>
      <title>Using `gcloud ... --format` with arbitrary returned data</title>
      <link>https://pretired.dazwilkin.com/posts/211022/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211022/</guid>
      <description>If you use jq, you&amp;rsquo;ll know that, its documentation uses examples that you can try locally or using the excellent jqplay:
printf &amp;#34;[1,2,3]&amp;#34; | jq .[1:] [ 2, 3 ] And here
If you use Google Cloud Platform (GCP) CLI, gcloud, this powerful tool includes JSON output formatting of results (--format=json) and YAML (--format=yaml) etc. and includes a set of so-called projections that you can use to format the returned data.</description>
    </item>
    
    <item>
      <title>Golang Structured Logging w/ Google Cloud Logging (2)</title>
      <link>https://pretired.dazwilkin.com/posts/211018/</link>
      <pubDate>Mon, 18 Oct 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211018/</guid>
      <description>UPDATE There&amp;rsquo;s an issue with my naive implementation of RenderValuesHook as described in this post. I summarized the problem in this issue where I&amp;rsquo;ve outlined (hopefully) a more robust solution.
Recently, I described how to configure Golang logging so that user-defined key-values applied to the logs are parsed when ingested by Google Cloud Logging.
Here&amp;rsquo;s an example of what we&amp;rsquo;re trying to achieve. This is an example Cloud Logging log entry that incorporates user-defined labels (see dog:freddie and foo:bar) and a readily-querable jsonPayload:</description>
    </item>
    
    <item>
      <title>Sigstore</title>
      <link>https://pretired.dazwilkin.com/posts/211007/</link>
      <pubDate>Thu, 07 Oct 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211007/</guid>
      <description>I&amp;rsquo;ve been on a digression (gcp-oidc-token-proxy) this week. Yesterday I began exploring Podman and wrote briefly about running gcp-oidc-token-proxy on my localhost using it.
This morning while walking with my dog, I listened to Google&amp;rsquo;s Dan Lorenc explain Sigstore (blog](https://blog.sigstore.dev/)) on The Kubelist Podcast1
The plan today is to try to sign the gcp-oidc-token-proxy container images in GitHub Container Registry.
NOTE I decided against trying the hardware key approach. I have a Google Titan key and only Yubikeys are well-tested by go-piv</description>
    </item>
    
    <item>
      <title>Podman</title>
      <link>https://pretired.dazwilkin.com/posts/211006/</link>
      <pubDate>Wed, 06 Oct 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211006/</guid>
      <description>I&amp;rsquo;ve read about Podman and been intrigued by it but never taken the time to install it and play around. This morning, walking with my dog, I listened to the almost-always-interesting Kubernetes Podcast and two of the principals behind Podman were on the show to discuss it.
I decided to install it and use it in this week&amp;rsquo;s project.
Here&amp;rsquo;s a working Podman deployment for gcp-oidc-token-proxy
ACCOUNT=&amp;#34;...&amp;#34; ENDPOINT=&amp;#34;...&amp;#34; # Can&amp;#39;t match container name i.</description>
    </item>
    
    <item>
      <title>Scraping metrics exposed by Google Cloud Run services that require authentication</title>
      <link>https://pretired.dazwilkin.com/posts/211005/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/211005/</guid>
      <description>I&amp;rsquo;ve written a solution (gcp-oidc-token-proxy) that can be used in conjunction with Prometheus OAuth2 to authenticate requests so that Prometheus can scrape metrics exposed by e.g. Cloud Run services that require authentication. The solution resulted from my question on Stack overflow.
Problem #1: Endpoint requires authentication
Given a Cloud Run service URL for which:
ENDPOINT=&amp;#34;my-server-blahblah-wl.a.run.app&amp;#34; # Returns 200 when authentication w/ an ID token TOKEN=&amp;#34;$(gcloud auth print-identity-token)&amp;#34; curl \ --silent \ --request GET \ --header &amp;#34;Authorization: Bearer ${TOKEN}&amp;#34; \ --write-out &amp;#34;%{response_code}&amp;#34; \ --output /dev/null \ https://${ENDPOINT}/metrics # Returns 403 otherwise curl \ --silent \ --request GET \ --write-out &amp;#34;%{response_code}&amp;#34; \ --output /dev/null \ https://${ENDPOINT}/metrics Problem #2: Prometheus OAuth2 configuration is constrained</description>
    </item>
    
    <item>
      <title>Golang Structured Logging w/ Google Cloud Logging</title>
      <link>https://pretired.dazwilkin.com/posts/210928/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210928/</guid>
      <description>I&amp;rsquo;ve multiple components in an app and these are deployed across multiple Google Cloud Platform (GCP) services: Kubernetes Engine, Cloud Functions, Cloud Run, etc. Almost everything is written in Golang and I started the project using go-logr.
logr is in two parts: a Logger that you use to write log entries; a LogSink (adaptor) that consumes log entries and outputs them to a specific log implementation.
Initially, I defaulted to using stdr which is a LogSink for Go&amp;rsquo;s standard logging implementation.</description>
    </item>
    
    <item>
      <title>GitHub help with dependency management</title>
      <link>https://pretired.dazwilkin.com/posts/210924/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210924/</guid>
      <description>This is very useful:
I am building an application that comprises multiple repos. I continue to procrastinate on whether using multiple repos vs. a monorepo was a good idea but, an issue that I have (had) is the need to ensure that the repos&amp;rsquo; contents are using current|latest modules. GitHub can help.
Most of the application is written in Golang with a smattering of Rust and some JavaScript.
Aside Even though I&amp;rsquo;m more proficient with Golang, I want to become more proficient in Rust and I contemplated trying to write the entire application in Rust.</description>
    </item>
    
    <item>
      <title>`gcloud beta run services replace`</title>
      <link>https://pretired.dazwilkin.com/posts/210907/</link>
      <pubDate>Mon, 06 Sep 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210907/</guid>
      <description>TL;DR I&amp;rsquo;m working on a project that includes multiple Cloud Run services. I&amp;rsquo;ve been putting my gcloud head on to deploy these services thinking that it&amp;rsquo;s curious there&amp;rsquo;s no way to write the specs as YAML configs. Today, I learned that there is: gcloud beta run services replace.
What prompted the discovery was some frustration trying to deploy a JSON-valued environment variable to Cloud Run:
local FIREBASE_CONFIG=&amp;#34;{ apiKey: ${FIREBASE_API_KEY}, authDomain: ${FIREBASE_AUTH_DOMAIN}, projectId: ${FIREBASE_PROJECT}, storageBucket: ${FIREBASE_STORAGE_BUCKET}, messagingSenderId: ${FIREBASE_MESSAGING_SENDER}, appId: ${FIREBASE_APP}}&amp;#34; gcloud run deploy ${SRV_NAME} \ --image=${IMAGE} \ --command=&amp;#34;/server&amp;#34; \ --args=&amp;#34;--endpoint=:${PORT}&amp;#34; \ --set-env-vars=FIREBASE_CONFIG=&amp;#34;${FIREBASE_CONFIG}&amp;#34; \ --max-instances=1 \ --memory=256Mi \ --ingress=all \ --platform=managed \ --port=${PORT} \ --allow-unauthenticated \ --region=${REGION} \ --project=${PROJECT} gcloud balks at this.</description>
    </item>
    
    <item>
      <title>Infrastructure as Code</title>
      <link>https://pretired.dazwilkin.com/posts/210902/</link>
      <pubDate>Thu, 02 Sep 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210902/</guid>
      <description>Problem I&amp;rsquo;m building an application that comprises:
Kubernetes¹ Kubernetes Operator Cloud Firestore Cloud Functions Cloud Run Cloud Endpoints Stripe Firebase Authentication ¹ - I&amp;rsquo;m using Google Kubernetes Engine (GKE) but may include other managed Kubernetes offerings (e.g. Digital Ocean, Linode, Oracle). GKE clusters are manageable by gcloud but other platforms require other CLI tools. All are accessible from bash but are these supported by e.g. Terraform (see below)?
Many of the components are packaged as container images and, because I&amp;rsquo;m using GitHub to host the project&amp;rsquo;s repos (I&amp;rsquo;ll leave the monorepo discussion for another post), I&amp;rsquo;ve become inculcated and use GitHub Container Registry (GHCR) as the container repo.</description>
    </item>
    
    <item>
      <title>Renewing Firebase Authentication ID tokens with gRPC</title>
      <link>https://pretired.dazwilkin.com/posts/210730/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210730/</guid>
      <description>I&amp;rsquo;ve written before about a project in which I&amp;rsquo;m using Firebase Authentication in combination with Google Cloud Endpoints and a gRPC service running on Cloud Run:
Firebase Authentication, Cloud Endpoints and gRPC (1of2) Firebase Authentication, Cloud Endpoints and gRPC (2of2) This works well with one caveat, the ID tokens (JWTs) minted by Firebase Authentication have a 3600 second (one hour) lifetime.
The user flow in my app is that whenever the user invokes the app&amp;rsquo;s CLI:</description>
    </item>
    
    <item>
      <title>gRPC Interceptors and in-memory gRPC connections</title>
      <link>https://pretired.dazwilkin.com/posts/210724/</link>
      <pubDate>Sat, 24 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210724/</guid>
      <description>For&amp;hellip; reasons, I wanted to pre-filter gRPC requests to check for authorization. Authorization is implemented as a &amp;lsquo;micro-service&amp;rsquo; and I wanted the authorization server to run in the same process as the gRPC client.
TL;DR:
Shiju&amp;rsquo;s &amp;ldquo;Writing gRPC Interceptors in Go&amp;rdquo; is great This Stack overflow answer ostensibly for writing unit tests for gRPC got me an in-process server What follows stands on these folks&amp;rsquo; shoulders&amp;hellip;
A key motivator for me to write blog posts is that helps me ensure that I understand things.</description>
    </item>
    
    <item>
      <title>Stripe</title>
      <link>https://pretired.dazwilkin.com/posts/210716/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210716/</guid>
      <description>It&amp;rsquo;s been almost a month since my last post. I&amp;rsquo;ve been occupied learning Stripe and integrating it into an application that I&amp;rsquo;m developing. The app benefits from a billing mechanism for prospective customers and, as far as I can tell, Stripe is the solution. I&amp;rsquo;d be interested in hearing perspectives on alternatives.
As with any platform, there&amp;rsquo;s good and bad and I&amp;rsquo;ll summarize my perspective on Stripe here. It&amp;rsquo;s been some time since I developed in JavaScript and this lack of familiarity has meant that the solution took longer than I wanted to develop.</description>
    </item>
    
    <item>
      <title>Firebase Authentication, Cloud Endpoints and gRPC (2of2)</title>
      <link>https://pretired.dazwilkin.com/posts/210618/</link>
      <pubDate>Fri, 18 Jun 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210618/</guid>
      <description>Earlier this week, I wrote about using Firebase Authentcation, Cloud Endpoints and gRPC (1of2). Since then, I learned some more and added a gRPC interceptor to implement basic authorization for the service.
ESPv2 --allow-unauthenticated The Cloud Enpoints (ESPv2) proxy must be run as --allow-unauthenticated on Cloud Run to ensure that requests make it to the proxy where the request is authenticated and only authenticated requests make it on to the backend service.</description>
    </item>
    
    <item>
      <title>Firebase Authentication, Cloud Endpoints and gRPC (1of2)</title>
      <link>https://pretired.dazwilkin.com/posts/210614/</link>
      <pubDate>Mon, 14 Jun 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210614/</guid>
      <description>I&amp;rsquo;m building a service that requires user authentication. The primary endpoint is a gRPC-based service. I would like to consider using certificate-based auth but this feels&amp;hellip; challenging. Instead, I have been aware of, but never used, Firebase Authentication and was interested to see that Cloud Endpoints includes Firebase Authentication as one of its supported auth mechanisms. Curiosity piqued, I confirmed that gRPC supports Google token-based authentication.
The following is a summary of what I did but I&amp;rsquo;ll leave the extensive documentation to Google, (Google&amp;rsquo;s) Firebase and gRPC, all of which, in this case, provide really good explanations.</description>
    </item>
    
    <item>
      <title>Cloud Endpoints combine OpenAPI and gRPC... or not!</title>
      <link>https://pretired.dazwilkin.com/posts/210608/</link>
      <pubDate>Tue, 08 Jun 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210608/</guid>
      <description>See:
Multiplexing gRPC and HTTP endpoints with Cloud Run gRPC, Cloud Run &amp;amp; Endpoints ESPv2: Configure Cloud Endpoints to proxy traffic to a Cloud Run multiplexed (gRPC|HTTP) service Challenges:
Cloud Run permits single port Cloud Run services publishing e.g. gRPC and Prometheus, must multiplex transports Cloud Run services publishing multiplexed transports are challenging to expose using Cloud Endpoints Hypothesis #1: Multiplexed transports work with Cloud Run See: Multiplexing gRPC and HTTP endpoints with Cloud Run</description>
    </item>
    
    <item>
      <title>Struggling with Golang structs</title>
      <link>https://pretired.dazwilkin.com/posts/210527/</link>
      <pubDate>Thu, 27 May 2021 16:06:08 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210527/</guid>
      <description>Julia&amp;rsquo;s post Blog about what you&amp;rsquo;ve struggled with resonates because I&amp;rsquo;ve been struggling with Golang structs in a project. Not the definitions of structs but seemingly needing to reproduce them across the project. I realize that each instance of these resources differs from the others but I&amp;rsquo;m particularly concerned by having to duplicate method implementations on them.
I&amp;rsquo;m kinda hoping that I see the solution to my problem by writing it out.</description>
    </item>
    
    <item>
      <title>Consul discovers Google Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/210520/</link>
      <pubDate>Thu, 20 May 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210520/</guid>
      <description>I&amp;rsquo;ve written a basic discoverer of Google Cloud Run services. This is for a project and it extends work done in some previous posts to Multiplex gRPC and Prometheus with Cloud Run and to use Consul for Prometheus service discovery.
This solution:
Accepts a set of Google Cloud Platform (GCP) projects Trawls them for Cloud Run services Assumes that the services expose Prometheus metrics on :443/metrics Relabels the services Surfaces any discovered Cloud Run services&amp;rsquo; metrics in Prometheus You&amp;rsquo;ll need Docker and Docker Compose.</description>
    </item>
    
    <item>
      <title>Multiplexing gRPC and HTTP (Prometheus) endpoints with Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/210519/</link>
      <pubDate>Wed, 19 May 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210519/</guid>
      <description>Google Cloud Run is useful but, each service is limited to exposing a single port. This caused me problems with a gRPC service that serves (non-gRPC) Prometheus metrics because customarily, you would serve gRPC on one port and the Prometheus metrics on another.
Fortunately, cmux provides a solution by providing a mechanism that multiplexes both services (gRPC and HTTP) on a single port!
TL;DR See the cmux Limitations and use:</description>
    </item>
    
    <item>
      <title>Firestore Golang Timestamps &amp; Merging</title>
      <link>https://pretired.dazwilkin.com/posts/210506/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210506/</guid>
      <description>I&amp;rsquo;m using Google&amp;rsquo;s Golang SDK for Firestore. The experience is excellent and I&amp;rsquo;m quikcly becoming a fan of Firestore. However, as a Golang Firestore developer, I&amp;rsquo;m feeling less loved and some of the concepts in the database were causing me a conundrum.
I&amp;rsquo;m still not entirely certain that I have Timestamps nailed but&amp;hellip; I learned an important lesson on the auto-creation of Timestamps in documents and how to retain these values.</description>
    </item>
    
    <item>
      <title>Prometheus Service Discovery w/ Consul for Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/210419/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:09 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210419/</guid>
      <description>I&amp;rsquo;m working on a project that will programmatically create Google Cloud Run services and I want to be able to dynamically discover these services using Prometheus.
This is one solution.
NOTE Google Cloud Run is the service I&amp;rsquo;m using, but the principle described herein applies to any runtime service that you&amp;rsquo;d wish to use.
Why is this challenging? IIUC, it&amp;rsquo;s primarily because Prometheus has a limited set of plugins for service discovery, see the sections that include _sd_ in Prometheus Configuration documentation.</description>
    </item>
    
    <item>
      <title>Cloud Firestore Triggers in Golang</title>
      <link>https://pretired.dazwilkin.com/posts/210413/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210413/</guid>
      <description>I was pleased to discover that Google provides a non-Node.JS mechanism to subscribe to and act upon Firestore triggers, Google Cloud Firestore Triggers. I&amp;rsquo;ve nothing against Node.JS but, for the project i&amp;rsquo;m developing, everything else is written in Golang. It&amp;rsquo;s good to keep it all in one language.
I&amp;rsquo;m perplexed that Cloud Functions still (!) only supports Go 1.13 (03-Sep-2019). Even Go 1.14 (25-Feb-2020) was released pre-pandemic and we&amp;rsquo;re now running on 1.</description>
    </item>
    
    <item>
      <title>Fly.io</title>
      <link>https://pretired.dazwilkin.com/posts/210412/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210412/</guid>
      <description>I spent some time over the weekend understanding Fly.io. It&amp;rsquo;s always fascinating to me how many smart people are building really neat solutions. Fly.io is subtly different to other platforms that I use (Kubernetes, GCP, DO, Linode) and I&amp;rsquo;ve found the Fly.io team to be highly responsive and helpful to my noob questions.
One of the team&amp;rsquo;s posts, Docker without Docker surfaced in my Feedly feed (hackernews) and it piqued my interest.</description>
    </item>
    
    <item>
      <title>Using Golang with the Firestore Emulator</title>
      <link>https://pretired.dazwilkin.com/posts/210317/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210317/</guid>
      <description>This works great but it wasn&amp;rsquo;t clearly documented for non-Firebase users. I assume it will work, as well, for any of the client libraries (not just Golang).
Assuming you have some (Golang) code (in this case using the Google Cloud Client Library) that interacts with a Firestore database. Something of the form:
package main import ( &amp;#34;context&amp;#34; &amp;#34;crypto/sha256&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;os&amp;#34; &amp;#34;time&amp;#34; &amp;#34;cloud.google.com/go/firestore&amp;#34; ) func hash(s string) string { h := sha256.</description>
    </item>
    
    <item>
      <title>Programmatically deploying Cloud Run services (Golang|Python)</title>
      <link>https://pretired.dazwilkin.com/posts/210316/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210316/</guid>
      <description>Phew! Programmitcally deploying Cloud Run services should be easy but it didn&amp;rsquo;t find it so.
My issues were that the Cloud Run Admin (!) API is poorly documented and it uses non-standard endpoints (thanks Sal!). Here, for others who may struggle with this, is how I got this to work.
Goal Programmatically (have Golang, Python, want Rust) deploy services to Cloud Run.
i.e. achieve this:
gcloud run deploy ${NAME} \ --image=${IMAGE} \ --platform=managed \ --no-allow-unauthenticated \ --region=${REGION} \ --project=${PROJECT} TRICK --log-http is your friend</description>
    </item>
    
    <item>
      <title>Prometheus VPA Recommendations</title>
      <link>https://pretired.dazwilkin.com/posts/210305/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210305/</guid>
      <description>Phew!
For Want of a Nail
I was interested in learning how to Manage Resources for Containers. On the way, I learned and discovered:
kubectl top Vertical Pod Autoscaler A (valuable) digression through PodMonitor kube-state-metrics `kubectl-patch Created a Graph References Kubernetes Resources Visual Studio Code has begun to bug me (reasonably) to add resources to Kubernetes manifests.
E.g.:
resources: limits: cpu: &amp;#34;1&amp;#34; memory: &amp;#34;512Mi&amp;#34; I&amp;rsquo;ve been spending time with Deislab&amp;rsquo;s Akri and decided to determine whether Akri&amp;rsquo;s primary resources (Agent, Controller) and some of my creations HTTP Device and Discovery, were being suitably constrained.</description>
    </item>
    
    <item>
      <title>Dapr</title>
      <link>https://pretired.dazwilkin.com/posts/210222/</link>
      <pubDate>Mon, 22 Feb 2021 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210222/</guid>
      <description>It&amp;rsquo;s a good name, I read it as &amp;ldquo;dapper&amp;rdquo; but I frequently type &amp;ldquo;darp&amp;rdquo; :-(
Was interested to read that Dapr is now v1.0 and decided to check it out. I was initially confused between Dapr and service mesh functionality. But, having used Dapr, it appears to be more focused in aiding the development of (cloud-native) (distributed) apps by providing developers with abstractions for e.g. service discovery, eventing, observability whereas service meshes feel (!</description>
    </item>
    
    <item>
      <title>Krustlet on DO Managed Kubernetes</title>
      <link>https://pretired.dazwilkin.com/posts/210122/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210122/</guid>
      <description>I&amp;rsquo;ve spent time this week returning to the interesting Deislabs project Krustlet. Since the last time, the bootstrapping process has been simplified using Kubernetes Bootstrap Tokens. I know this updated process works with MicroK8s. Unfortunately, I&amp;rsquo;m struggling with it on GKE and thought I&amp;rsquo;d try DigitalOcean Managed Kubernetes.
It worked first time!
In the following, we run both the Kubernetes cluster and the Krustlet Droplet on DigitalOcean but, as long as the cluster and the VM are able to communicate with one another, you should be able to run these anywhere.</description>
    </item>
    
    <item>
      <title>Kubernetes cert-manager</title>
      <link>https://pretired.dazwilkin.com/posts/210108/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210108/</guid>
      <description>I developed an admission webhook for Akri, twice (Golang, Rust). I naively followed other examples for the generation of the certificates, created a 1.20 cluster and broke that process.
I&amp;rsquo;d briefly considered using cert-manager recently but quickly abandoned the idea thinking it would be onerous and unnecessary complexity for little-old-me. I was wrong. It&amp;rsquo;s excellent and I recommend it highly.
I won&amp;rsquo;t reproduce the v1beta1 and v1 examples from the Stackoverflow question as they should be self-explanatory.</description>
    </item>
    
    <item>
      <title>Kubernetes Webhooks</title>
      <link>https://pretired.dazwilkin.com/posts/201229/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201229/</guid>
      <description>I spent some time last week writing my first admission webhook for Kubernetes. I wrote the handler in Golang because I&amp;rsquo;m most familiar with Golang and because, as Kubernetes&amp;rsquo; native language, I was more confident that the necessary SDKs would exist and that the documentation would likely use Golang by default. I struggled to find useful documentation and so this post is to help you (and me!) remember how to do this next time!</description>
    </item>
    
    <item>
      <title>Kubernetes Device Plugins</title>
      <link>https://pretired.dazwilkin.com/posts/201217/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201217/</guid>
      <description>I&amp;rsquo;m debugging an issue with Akri Zeroconf protocol in which Instance environment variables are no longer (!) being surfaced within the Broker pods. In my adventures, it seemed useful to better understand how Akri works and specifically, how Akri uses Kubernetes Device Plugins.
IIUC plugins register with the Kubelet (!) via a gRPC service (Registration) that the Kubelet exposes on a UNIX socket at /var/lib/kubelet/device-plugins/kubelet.sock
Then (!) if successful, devices should be reported by the Node&amp;rsquo;s metadata (spec) and available to be bound to Pods.</description>
    </item>
    
    <item>
      <title>webmention</title>
      <link>https://pretired.dazwilkin.com/posts/201203/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201203/</guid>
      <description>Let&amp;rsquo;s see if this works!?
I&amp;rsquo;ve added the following link to this site&amp;rsquo;s baseof.html so that it is now rendered for each page:
&amp;lt;link href=&amp;#34;https://us-central1-webmention.cloudfunctions.net/webmention&amp;#34; rel=&amp;#34;webmention&amp;#34; /&amp;gt; I discovered indieweb yesterday reading about webmention. Who knows what got me to webmention!?
The principles of both are sound. Instead of relying on come-go behemoths to run our digital world, indieweb seeks to provide technologies that enable us to achieve things without them.</description>
    </item>
    
    <item>
      <title>pest: parsing in Rust</title>
      <link>https://pretired.dazwilkin.com/posts/201202/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201202/</guid>
      <description>A Microsoft engineer introduced me to pest as a way to introduce service filtering in a ZeroConf plugin that I&amp;rsquo;m prototyping for Akri. It&amp;rsquo;s been fun to learn but I worry that, because I won&amp;rsquo;t use it frequently, I&amp;rsquo;m going to quickly forget what I&amp;rsquo;ve done. So, here are my notes.
Here&amp;rsquo;s the problem, I&amp;rsquo;d like to be able to provide users of the ZeroConf plugin with a string-based filter that permits them to filter the services discovered when the Akri agent browses a network.</description>
    </item>
    
    <item>
      <title>Akri</title>
      <link>https://pretired.dazwilkin.com/posts/201113/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201113/</guid>
      <description>For the past couple of weeks, I&amp;rsquo;ve been playing around with Akri, a Microsoft (DeisLabs) project for building a connected edge with Kubernetes. Kubernetes, IoT, Rust (and Golang) make this all compelling to me.
Initially, I deployed an Akri End-to-End to MicroK8s on Google Compute Engine (link) and Digital Ocean (link). But I was interested to create me own example and so have proposed a very (!) simple HTTP-based protocol.</description>
    </item>
    
    <item>
      <title>GitHub Actions &amp;&amp; GitHub Container Registry</title>
      <link>https://pretired.dazwilkin.com/posts/201029/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201029/</guid>
      <description>You know when you start something and then regret it!? I think I&amp;rsquo;ll be sticking with Google Cloud Build; GitHub Actions appears functional and useful but I found the documentation to be confusing and limited and struggled to get a simple container image build|push working.
I&amp;rsquo;ve long used Docker Hub but am planning to use it less as a result of the planned changes. I want to see Docker succeed and to do so it needs to find a way to make money but, there are free alternatives including the new GitHub Container Registry and the very very cheap Google Container Registry.</description>
    </item>
    
    <item>
      <title>akri</title>
      <link>https://pretired.dazwilkin.com/posts/201022/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201022/</guid>
      <description>I was very interested to read about Microsoft&amp;rsquo;s DeisLab&amp;rsquo;s latest (rust-based) Kubernetes project: akri. If I understand it correctly, it provides a mechanism to make any (IoT) device accessible to containers running within a cluster. I need to spend more time playing around with it so that I can fully understand it. I had some problems getting the End-to-End demo running on Google Compute Engine (and then I tried DigitalOcean droplet) instances.</description>
    </item>
    
    <item>
      <title>Deploying a Rust HTTP server to DigitalOcean App Platform</title>
      <link>https://pretired.dazwilkin.com/posts/201008/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/201008/</guid>
      <description>DigitalOcean launched an App Platform with many Supported Languages and Frameworks. I used Golang first, then wondered how to use non-natively-supported languages, i.e. Rust.
The good news is that Docker is a supported framework and so, you can run pretty much anything.
Repo: https://github.com/DazWilkin/do-apps-rust
Rust I&amp;rsquo;m a Rust noob. I&amp;rsquo;m always receptive to feedback on improvements to the code. I looked to mirror the Golang example. I&amp;rsquo;m using rocket and rocket-prometheus for the first time:</description>
    </item>
    
    <item>
      <title>Hugo and Google Cloud Storage</title>
      <link>https://pretired.dazwilkin.com/posts/200930/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200930/</guid>
      <description>I&amp;rsquo;m using Hugo as a static site generator for this blog. I&amp;rsquo;m using Firebase (for free) to host lefsilver.
I have other domains that I want to promote and decided to use Google Cloud Storage buckets for these sites. Using Google Cloud Storage for Hosting a static website and using Hugo to deploy sites to Google Cloud Storage (GCS) are documented but, I didn&amp;rsquo;t find a location where this is combined into a single tutorial and I wanted to add an explanation for ensuring your sites are included in Google&amp;rsquo;s and Bing&amp;rsquo;s search indexes.</description>
    </item>
    
    <item>
      <title>Rube Goldberg Cloud Build machine for solving Quadratic equations</title>
      <link>https://pretired.dazwilkin.com/posts/200928/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200928/</guid>
      <description>Google Cloud Build is described by Google as a &amp;ldquo;CI/CD platform&amp;rdquo; but it&amp;rsquo;s fundamentally a service that permits a series of containers to be chained together in a pipeline, optionally leveraging shared data.
As a CI/CD platform, it can be used to lint, test, compile and build software but, if you were looking for a way to explain its basic awesomeness, you could&amp;hellip; I don&amp;rsquo;t know&amp;hellip; build a Rube Goldberg style machine that solves Quadratic equations using it 😄</description>
    </item>
    
    <item>
      <title>Visual Studio Code plus Google Cloud Shell</title>
      <link>https://pretired.dazwilkin.com/posts/200917/</link>
      <pubDate>Thu, 17 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200917/</guid>
      <description>Update: 2020-09-24 Three updates since I wrote the post:
gcloud alpha cloud-shell get-mount-command ${DIR} It&amp;rsquo;s possible to use sshfs to mount the Cloud Shell home directory locally:
DIR=/path/to/dir gcloud alpha cloud-shell get-mount-command ${DIR} Which generates something of the form:
sshfs [[USERNAME]]@[[HOST]]: ${DIR} \ -p [[PORT]] \ -oIdentityFile=~/.ssh/google_compute_engine \ -oStrictHostKeyChecking=no You may then code --new-window ${DIR}
curl command may lack .sshHost curl&amp;rsquo;ing the cloudshell.googleapis.com endpoint will result in a null value for .</description>
    </item>
    
    <item>
      <title>Actions SDK Conversational Quickstart</title>
      <link>https://pretired.dazwilkin.com/posts/200916/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200916/</guid>
      <description>Google&amp;rsquo;s tutorial didn&amp;rsquo;t work for me.
In this post, I&amp;rsquo;ll help you get this working.
https://developers.google.com/assistant/conversational/quickstart
Create and set up a project This mostly works.
I recommend using the Actions Console as described to create the project.
I chose &amp;ldquo;Custom&amp;rdquo; and &amp;ldquo;Blank Project&amp;rdquo;
You need not enable Actions API as this is done automatically:
For the console work, I&amp;rsquo;m going to use Google&amp;rsquo;s excellent Cloud Shell. You may access this through the browser or through a terminal:</description>
    </item>
    
    <item>
      <title>Trillian Map Mode</title>
      <link>https://pretired.dazwilkin.com/posts/200908/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200908/</guid>
      <description>Chatting with one of Google&amp;rsquo;s Trillian team, I was encouraged to explore Trillian&amp;rsquo;s Map Mode. The following is the result of some spelunking through this unfamiliar cave. I can&amp;rsquo;t provide any guarantee that this usage is correct or sufficient.
Here&amp;rsquo;s the repo: https://github.com/DazWilkin/go-trillian-map
I&amp;rsquo;ve written about Trillian Log Mode elsewhere.
I uncovered use of Trillian Map Mode through Trillian&amp;rsquo;s integration tests. I&amp;rsquo;m unclear on the distinction between TrillianMapClient and TrillianMapWriteClient but the latter served most of my needs.</description>
    </item>
    
    <item>
      <title>Minimizing WASM binaries</title>
      <link>https://pretired.dazwilkin.com/posts/200819/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200819/</guid>
      <description>I&amp;rsquo;ve spent time recently playing around with WebAssembly (WASM) and waPC. Rust and WASM were born at Mozilla and there&amp;rsquo;s a natural affinity with writing WASM binaries in Rust. In the WASM examples I&amp;rsquo;ve been using for WASM Transparency, waPC and MsgPack and waPC and Protobufs.
I&amp;rsquo;ve created 3 WASM binaries: complex.wasm, simplex.wasm and fabcar.wasm and each is about 2.5MB when:
cargo build --target=wasm32-unknown-unknown --release The Rust and WebAssembly book has an excellent section titled Shrinking .</description>
    </item>
    
    <item>
      <title>WASM Transparency</title>
      <link>https://pretired.dazwilkin.com/posts/200817/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200817/</guid>
      <description>I&amp;rsquo;ve been playing around with a proof-of-concept combining WASM and Trillian. The hypothesis was to explore using WASM as a form of chaincode with Trillian. The project works but it&amp;rsquo;s far from being a chaincode-like solution.
Let&amp;rsquo;s start with a couple of (trivial) examples and then I&amp;rsquo;ll explain what&amp;rsquo;s going on and how it&amp;rsquo;s implemented.
2020/08/14 18:42:17 [main:loop:dynamic-invoke] Method: mul 2020/08/14 18:42:17 [random:New] Message 2020/08/14 18:42:17 [random:New] Float32 2020/08/14 18:42:17 [random:New] Float32 2020/08/14 18:42:17 [random:New] Message 2020/08/14 18:42:17 [random:New] Float32 2020/08/14 18:42:17 [random:New] Float32 2020/08/14 18:42:17 [Client:Invoke] Metadata: complex.</description>
    </item>
    
    <item>
      <title>waPC and MsgPack (Rust|Golang)</title>
      <link>https://pretired.dazwilkin.com/posts/200807/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200807/</guid>
      <description>As my reader will know (Hey Mom!), I&amp;rsquo;ve been noodling around with WASM and waPC. I&amp;rsquo;ve been exploring ways to pass structured messages across the host:guest boundary.
Protobufs was my first choice. @KevinHoffman created waPC and waSCC and he explained to me and that wSCC uses Message Pack.
It&amp;rsquo;s slightly surprising to me (still) that technologies like this exist with everyone else seemingly using them and I&amp;rsquo;ve not heard of them.</description>
    </item>
    
    <item>
      <title>Envoy WASM filters in Rust</title>
      <link>https://pretired.dazwilkin.com/posts/200723/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200723/</guid>
      <description>A digression thanks to Sal Rashid who&amp;rsquo;s exploring WASM filters w/ Envoy.
The documentation is sparse but:
How to write WASM filters for Envoy&amp;hellip; There is a Rust SDK but it&amp;rsquo;s not documented:
proxy-wasm-rust-sdk I found two useful posts by Rustaceans who were able to make use of it:
Extending Envoy with WASM and Rust Extending Istio with Rust and WebAssembly Here&amp;rsquo;s my simple use of the SDK&amp;rsquo;s examples.
wasme curl -sL https://run.</description>
    </item>
    
    <item>
      <title>Remotely invoking WASM functions using gRPC and waPC</title>
      <link>https://pretired.dazwilkin.com/posts/200717/</link>
      <pubDate>Fri, 17 Jul 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200717/</guid>
      <description>Following on from waPC &amp;amp; Protobufs, I can now remotely invoke (arbitrary) WASM functions:
Client:
The logging isn&amp;rsquo;t perfectly clear but, the client gets (a previously added) WASM binary from the server (using the SHA-256 of the WASM binary as a unique identifier). The result includes metadata that includes a protobuf descriptor of the WASM binary&amp;rsquo;s functions. The descriptor defines gRPC services (that represent the WASM functions) with input (parameters) and output (results) messages.</description>
    </item>
    
    <item>
      <title>Golang Protobuf APIv2</title>
      <link>https://pretired.dazwilkin.com/posts/200630/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200630/</guid>
      <description>Google has a new Golang Protobuf API, APIv2 (google.golang.org/protobuf) superseding APIv1 (github.com/golang/protobuf). If your code is importing github.com/golang/protobuf, you&amp;rsquo;re using APIv2. Otherwise, you should consult with the docs because Google reimplemented APIv1 atop APIv2. One challenge this caused me, as someone who does not use protobufs and gRPC on a daily basis, is that gRPC (code-generation) is being removed from the (Golang) protoc-gen-go, the Golang plugin that generates gRPC service bindings.</description>
    </item>
    
    <item>
      <title>WASM Cloud Functions</title>
      <link>https://pretired.dazwilkin.com/posts/200617/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200617/</guid>
      <description>Following on from waPC &amp;amp; Protobufs and a question on Stack Overflow about Cloud Functions, I was compelled to try running WASM on Cloud Functions no JavaScript.
I wanted to reuse the WASM waPC functions that I&amp;rsquo;d written in Rust as described in the other post. Cloud Functions does not (yet!?) provide a Rust runtime and so I&amp;rsquo;m using the waPC Host for Go in this example.
It works!
PARAMS=$(printf &amp;#39;{&amp;#34;a&amp;#34;:{&amp;#34;real&amp;#34;:39,&amp;#34;imag&amp;#34;:3},&amp;#34;b&amp;#34;:{&amp;#34;real&amp;#34;:39,&amp;#34;imag&amp;#34;:3}}&amp;#39; | base64) TOKEN=$(gcloud auth print-identity-token) echo &amp;#34;{ \&amp;#34;filename\&amp;#34;:\&amp;#34;complex.</description>
    </item>
    
    <item>
      <title>waPC &amp; Protobufs</title>
      <link>https://pretired.dazwilkin.com/posts/200612/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200612/</guid>
      <description>I&amp;rsquo;m hacking around with a solution that combines WASM and Google Trillian.
Ultimately, I&amp;rsquo;d like to be able to ship WASM (binaries) to a Trillian personality and then invoke (exported) functions on them. Some this was borne from the interesting exploration of Krustlet and its application of wascc.
I&amp;rsquo;m still booting into WASM but it&amp;rsquo;s a very interesting technology that has most interesting potential outside the browser. Some folks have been trailblazing the technology and I have been reading Kevin Hoffman&amp;rsquo;s medium and wascc (nee waxosuit) work.</description>
    </item>
    
    <item>
      <title>Google Container Registry w/ OCI</title>
      <link>https://pretired.dazwilkin.com/posts/200508/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200508/</guid>
      <description>I&amp;rsquo;ve been spending some time this week with Krustlet.
I&amp;rsquo;m working on documenting how to run Krustlet(s) alongside GKE. I&amp;rsquo;ve been running a Krustlet with MicroK8s.
The Krustlet demos reference WASM assemblines stored in Azure Container Registry as OCI containers. Google Container Registry supports OCI format and so I tried (successfully) using GCR instead of AZR.
There may be an easier approach but this is how I got this working.</description>
    </item>
    
    <item>
      <title>Rust implementation of Crate Transparency using Google Trillian</title>
      <link>https://pretired.dazwilkin.com/posts/200429/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200429/</guid>
      <description>I&amp;rsquo;ve been hacking on a Rust-based transparent application for Google Trillian. As appears to be my fixation, this personality is for another package manager. This time, Rust&amp;rsquo;s Crates often found in crates.io which is Rust&amp;rsquo;s Package Registry. I discussed this project earlier this month Rust Crate Transparency &amp;amp;&amp;amp; Rust SDK for Google Trillian and and earlier approach for Python&amp;rsquo;s packages with pypi-transparency.
This time, of course, I&amp;rsquo;m using Rust. And, by way of a first for me, for the gRPC server implementation (aka &amp;ldquo;personality&amp;rdquo;).</description>
    </item>
    
    <item>
      <title>Golang Xiaomi Bluetooth Temperature|Humidity (LYWSD03MMC) 2nd Gen</title>
      <link>https://pretired.dazwilkin.com/posts/200417/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200417/</guid>
      <description>Well, this became more of an adventure that I&amp;rsquo;d originally wanted but, after learning some BLE and, with the help of others (Thanks Jonatha, JsBergbau), I&amp;rsquo;ve sample code that connects to 4 Xiaomi 2nd gen. Thermometers, subscribes to readings and publishes the data to MQTT. From there, I&amp;rsquo;m scraping it using Inuits MQTTGateway into Prometheus.
Repo: https://github.com/DazWilkin/gomijia2
Thanks|Credit: Jonathan McDowell for gomijia and help JsBergbau for help Background I&amp;rsquo;ve been playing around with ESPHome and blogged around my very positive experience ESPHome, MQTT, Prometheus and almost Cloud IoT.</description>
    </item>
    
    <item>
      <title>Rust Crate Transparency &amp;&amp; Rust SDK for Google Trillian</title>
      <link>https://pretired.dazwilkin.com/posts/200403/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200403/</guid>
      <description>I&amp;rsquo;m noodling the utility of a Transparency solution for Rust Crates. When developers push crates to Cargo, a bunch of metadata is associated with the crate. E.g. protobuf. As with Golang Modules, Python packages on PyPi etc., there appears to be utility in making tamperproof recordings of these publications. Then, other developers may confirm that a crate pulled from cates.io is highly unlikely to have been changed.
On Linux, Cargo stores downloaded crates under ${HOME}/.</description>
    </item>
    
    <item>
      <title>Google Trillian on Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/200326/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200326/</guid>
      <description>I&amp;rsquo;ve written previously (Google Trillian for Noobs) about Google&amp;rsquo;s interesting project Trillian and about some of the &amp;ldquo;personalities&amp;rdquo; (e.g. PyPi Transparency) that I&amp;rsquo;ve build using it.
Having gone slight cra-cra on Cloud Run and gRPC this week with Golang gRPC Cloud Run and gRPC, Cloud Run &amp;amp; Endpoints, I thought it&amp;rsquo;d be fun to deploy Trillian and a personality to Cloud Run.
It mostly (!) works :-)
At the end of the post, I&amp;rsquo;ve summarized creating a Cloud SQL instance to host the Trillian data(base).</description>
    </item>
    
    <item>
      <title>gRPC, Cloud Run &amp; Endpoints</title>
      <link>https://pretired.dazwilkin.com/posts/200325/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200325/</guid>
      <description>&amp;lt;3 Google but there&amp;rsquo;s quite often an assumption that we&amp;rsquo;re all sitting around the engineering table and, of course, we&amp;rsquo;re not.
Cloud Endpoints is a powerful offering but &amp;ndash; IMO &amp;ndash; it&amp;rsquo;s super confusing to understand and complex to deploy.
If you&amp;rsquo;re familiar with the motivations behind service meshes (e.g. Istio), Cloud Endpoints fits in a similar niche (&amp;ldquo;neesh&amp;rdquo; or &amp;ldquo;nitch&amp;rdquo;?). The underlying ambition is that, developers can take existing code and by adding a proxy (or sidecar), general-purpose abstractions, security, logging etc.</description>
    </item>
    
    <item>
      <title>Golang gRPC Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/200320/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200320/</guid>
      <description>Update: 2020-03-24: Since writing this post, I&amp;rsquo;ve contributed Golang and Rust samples to Google&amp;rsquo;s project. I recommend you start there.
Google explained how to run gRPC servers with Cloud Run. The examples are good but only Python and Node.JS:
gRPC comes to Cloud Run gRPC in Google Cloud Run Missing Golang&amp;hellip;. until now ;-)
I had problems with 1.14 and so I&amp;rsquo;m using 1.13.
Project structure I&amp;rsquo;ll tidy up my repo but the code may be found:</description>
    </item>
    
    <item>
      <title>OriginStamp Rust SDK Example</title>
      <link>https://pretired.dazwilkin.com/posts/200312/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200312/</guid>
      <description>I wrote recently describing Python and Golang clients for OriginStamp based on OriginStamp&amp;rsquo;s API&amp;rsquo;s swagger spec. As a way to pursue learning rust, I&amp;rsquo;ve been forcing myself to write examples using rust. I&amp;rsquo;m honestly finding learning rust tough going and think I&amp;rsquo;m probably better to revert to the &amp;ldquo;Learning Rust&amp;rdquo; tutorials.
That said, herewith an explanation of building a rust client using an OpenAPI (!) generated SDK from OriginStamp&amp;rsquo;s swagger spec.</description>
    </item>
    
    <item>
      <title>Google&#39;s New Golang SDK for Protobufs</title>
      <link>https://pretired.dazwilkin.com/posts/200310/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200310/</guid>
      <description>Google has released a new Golang SDK for protobuf. In the [announcement], a useful tool to redact properties is described. If like me, this is somewhat novel to you, here&amp;rsquo;s a mashup using Google&amp;rsquo;s Protocol Buffer Basics w/ redaction.
To be very clear, as it&amp;rsquo;s an important distinction:
Version Repo Docs v2 google.golang.org/protobuf Docs v1 github.com/golang/protobuf Docs Project Here&amp;rsquo;s my project structure:
. ├── protoc-3.11.4-linux-x86_64 │ ├── bin │ │ └── protoc │ ├── include │ │ └── google │ └── readme.</description>
    </item>
    
    <item>
      <title>ESPHome, MQTT, Prometheus and almost Cloud IoT</title>
      <link>https://pretired.dazwilkin.com/posts/200227/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200227/</guid>
      <description>ESPHome is a very interesting project. I&amp;rsquo;d not heard of it until this week and am surprised that it isn&amp;rsquo;t more newsworthy.
I&amp;rsquo;m always tinkering with IoT stuff, have a couple of Wemos D1 ESP8266s. They are brought out occasionally for learning. I&amp;rsquo;ve been using them this week with ESPHome. I&amp;rsquo;m looking to buy some Xiaomi BLE temperature sensors and thinking I could read the temperatures from these using the ESPs (thanks to ESPHome) and publish the data to MQTT.</description>
    </item>
    
    <item>
      <title>OriginStamp: Verifying Proofs</title>
      <link>https://pretired.dazwilkin.com/posts/200226/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200226/</guid>
      <description>Recently, I wrote about some initial adventures with OriginStamp
Using OriginStamp&amp;rsquo;s UI or API, submitting a hash results in transactions being submitted to Bitcoin, Ethereum and a German newspaper.
Using the API, it&amp;rsquo;s possible to query OriginStamp&amp;rsquo;s service for a proof. This post explains how to verify such a proof.
The diligent reader among you (Hey Mom!) will recall that I submitted a hash for the message:
Frederik Jack is a bubbly Border Collie The SHA-256 hash of this message is:</description>
    </item>
    
    <item>
      <title>FreeTSA &amp; Digitorus&#39; Timestamp SDK</title>
      <link>https://pretired.dazwilkin.com/posts/200219/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200219/</guid>
      <description>I wrote recently about some exploration of Timestamping with OriginStamp. Since writing that post, I had some supportive feedback from the helpful folks at OriginStamp and plan to continue exploring that solution.
Meanwhile, OriginStamp exposed me to timestamping and trusted timestamping and I discovered freeTSA.org.
What&amp;rsquo;s the point? These services provide authoritative proof of the existence of a digital asset before some point in time; OriginStamp provides a richer service and uses multiple timestamp authorities including Bitcoin, Ethereum and rather interestingly a German Newspaper&amp;rsquo;s Trusted Timestamp.</description>
    </item>
    
    <item>
      <title>OriginStamp Python|Golang SDK Examples</title>
      <link>https://pretired.dazwilkin.com/posts/200217/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200217/</guid>
      <description>A friend mentioned OriginStamp to me.
NB There are 2 sites: originstamp.com and originstamp.org.
It&amp;rsquo;s an interesting project.
It&amp;rsquo;s a solution for providing auditable proof that you had a(ccess to) some digital thing before a certain date. OriginStamp provides user-|developer-friendly means to submit files|hashes (of your content) and have these bundled into transactions that are submitted to e.g. bitcoin.
I won&amp;rsquo;t attempt to duplicate the narrative here, review OriginStamp&amp;rsquo;s site and some of its content.</description>
    </item>
    
    <item>
      <title>Accessing GCR repos from Kubernetes</title>
      <link>https://pretired.dazwilkin.com/posts/200207/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200207/</guid>
      <description>Until today, I&amp;rsquo;d not accessed a Google Container Registry repo from a non-GKE Kubernetes deployment.
It turns out that it&amp;rsquo;s pretty well-documented (link) but, here&amp;rsquo;s an end-end example.
Assuming:
BILLING=[[YOUR-BILLING]] PROJECT=[[YOUR-PROJECT]] SERVER=&amp;#34;us.gcr.io&amp;#34; If not already:
gcloud projects create {$PROJECT} gcloud beta billing projects link ${PROJECT} \ --billing-account=${BILLING} gcloud services enable containerregistry.googleapis.com \ --project=${PROJECT} Container Registry IMAGE=&amp;#34;busybox&amp;#34; # Or ... docker pull ${IMAGE} docker tag \ ${IMAGE} \ ${SERVER}/${PROJECT}/${IMAGE} docker push ${SERVER}/${PROJECT}/${IMAGE} gcloud container images list-tags ${SERVER}/${PROJECT}/${IMAGE} Service Account Create a service account that&amp;rsquo;s permitted to download (read-only) images from this project&amp;rsquo;s registry</description>
    </item>
    
    <item>
      <title>Cloud Build wishlist: Mountable Golang Modules Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/200206/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200206/</guid>
      <description>I think it would be valuable if Google were to provide volumes in Cloud Build of package registries (e.g. Go Modules; PyPi; Maven; NPM etc.).
Google provides a mirror of a subset of Docker Hub. This confers several benefits: Google&amp;rsquo;s imprimatur; speed (latency); bandwidth; and convenience.
The same benefits would apply to package registries.
In the meantime, there&amp;rsquo;s a hacky way to gain some of the benefits of these when using Cloud Build.</description>
    </item>
    
    <item>
      <title>Setting up a GCE Instance as an Inlets Exit Node</title>
      <link>https://pretired.dazwilkin.com/posts/200122/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200122/</guid>
      <description>The prolific Alex Ellis has a new project, Inlets.
Here&amp;rsquo;s a quick tutorial using Google Compute Platform&amp;rsquo;s (GCP) Compute Engine (GCE).
NB I&amp;rsquo;m using one of Google&amp;rsquo;s &amp;ldquo;Always free&amp;rdquo; f1-micro instances but you may still pay for network *gress and storage
Assumptions I&amp;rsquo;m assuming you&amp;rsquo;ve a Google account, have used GCP and have a billing account established, i.e. the following returns at least one billing account:
gcloud beta billing accounts list If you&amp;rsquo;ve only one billing account and it&amp;rsquo;s the one you wish to use, then you can:</description>
    </item>
    
    <item>
      <title>Trendnet TEW-812DRU and DD-WRT</title>
      <link>https://pretired.dazwilkin.com/posts/200113/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200113/</guid>
      <description>The FBI Portland published an interesting advisory with several, sensible recommendations including firewalling IoT devices from other devices on a home network. I decided to deploy a redundant Trendnet TEW-812DRU version 2.0 for this purpose.
Caveat Developer: Before I go further, I don&amp;rsquo;t recommend installing DD-WRT on a Trendnet TEW-812DRU unless you&amp;rsquo;re willing to brick the device irrecoverably.
I read the DD-WRT instructions several times (&amp;ldquo;peacock thread&amp;rdquo;,router database &amp;ndash; do not use v3.</description>
    </item>
    
    <item>
      <title>Google Fit</title>
      <link>https://pretired.dazwilkin.com/posts/200110/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200110/</guid>
      <description>I&amp;rsquo;ve spent a few days exploring [Google Fit SDK] as I try to wean myself from my obsession with metrics (of all forms). A quick Googling got me to Robert&amp;rsquo;s Exporter Google Fit Daily Steps, Weight and Distance to a Google Sheet. This works and is probably where I should have stopped&amp;hellip; avoiding the rabbit hole that I&amp;rsquo;ve been down&amp;hellip;
I threw together a simple Golang implementation of the SDK using Google&amp;rsquo;s Golang API Client Library.</description>
    </item>
    
    <item>
      <title>Google Home Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/200107/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200107/</guid>
      <description>I&amp;rsquo;m obsessing over Prometheus exporters. First came Linode Exporter, then GCP Exporter and, on Sunday, I stumbled upon a reverse-engineered API for Google Home devices and so wrote a very basic Google Home SDK and a similarly basic Google Home Exporter:
The SDK only implements /setup/eureka_info and then only some of the returned properties. There&amp;rsquo;s not a lot of metric-like data to use besides SignalLevel (signal_level) and NoiseLevel (noise_level). I&amp;rsquo;m not clear on the meaning of some of the properties.</description>
    </item>
    
    <item>
      <title>Adventures around BPF</title>
      <link>https://pretired.dazwilkin.com/posts/191230/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191230/</guid>
      <description>I think (!?) this interesting learning experience started with Envoy Go Extensions.
IIUC, Cilium contributed this mechanism (Envoy Go Extensions) by which it&amp;rsquo;s possible to extend Envoy using Golang. The documentation references BPF. Cilium and BNF were both unfamiliar technologies to me and so began my learning. This part of the journey concludes with Weave Scope.
I learned that Cilium is a CNI implementation that may be used with Kubernetes. GKE defaults (but is not limited to) to Google&amp;rsquo;s own CNI implementation (link).</description>
    </item>
    
    <item>
      <title>Google Cloud Platform (GCP) Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191220/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191220/</guid>
      <description>Earlier this week I discussed a Linode Prometheus Exporter.
I added metrics for Digital Ocean&amp;rsquo;s Managed Kubernetes service to @metalmatze&amp;rsquo;s Digital Ocean Exporter.
This left, metrics for Google Cloud Platform (GCP) which has, for many years, been my primary cloud platform. So, today I wrote Prometheus Exporter for Google Cloud Platform.
All 3 of these exporters follow the template laid down by @metalmatze and, because each of these services has a well-written Golang SDK, it&amp;rsquo;s straightforward to implement an exporter for each of them.</description>
    </item>
    
    <item>
      <title>Prometheus AlertManager</title>
      <link>https://pretired.dazwilkin.com/posts/191219/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191219/</guid>
      <description>Yesterday I discussed a Linode Prometheus Exporter and tantalized use of Prometheus AlertManager.
Success:
Configure The process is straightforward although I found the Prometheus (config) documentation slightly unwieldy to navigate :-(
The overall process is documented.
Here are the steps I took:
Configure Prometheus Configure AlertManager Revise Docker Compose Configure Prometheus Added the following to prometheus.yml:
rule_files: - &amp;#34;/etc/alertmanager/rules/linode.yml&amp;#34; alerting: alertmanagers: - scheme: http static_configs: - targets: - &amp;#34;alertmanager:9093&amp;#34; Rules must be defined in separate rules files.</description>
    </item>
    
    <item>
      <title>Linode Prometheus Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191218/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191218/</guid>
      <description>I enjoy using Prometheus and have toyed around with it for some time particularly in combination with Kubernetes. I signed up with Linode [referral] compelled by the addition of a managed Kubernetes service called Linode Kubernetes Engine (LKE). I have an anxiety that I&amp;rsquo;ll inadvertently leave resources running (unused) on a cloud platform. Instead of refreshing the relevant billing page, it struck me that Prometheus may (not yet proven) help.</description>
    </item>
    
    <item>
      <title>NGINX Ingress</title>
      <link>https://pretired.dazwilkin.com/posts/191211/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191211/</guid>
      <description>I&amp;rsquo;ve written a couple of deployment options (Google Compute Engine; Kubernetes) for an open-source project. The Kubernetes deployment provides NodePort and (TCP) LoadBalancer options and I&amp;rsquo;ve been trying (unsuccessfully) to add HTTPS Load-balancing.
I should (!) try to deploy to Google Kubernetes Engine (GKE) but I&amp;rsquo;ve been using microk8s, Digital Ocean Managed Kubernetes and the Linode LKE Beta. Each of these requires an implementation of Ingress controller. For GKE, GCP&amp;rsquo;s HTTP/S Load-balancer (GCLB) is used.</description>
    </item>
    
    <item>
      <title>PyPi Transparency Client (Rust)</title>
      <link>https://pretired.dazwilkin.com/posts/190930/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190930/</guid>
      <description>I&amp;rsquo;ve finally being able to hack my way through to a working Rust gRPC client (for PyPi Transparency).
It&amp;rsquo;s not very good: poorly structured, hacky etc. but it serves the purpose of giving me a foothold into Rust development so that I can evolve it as I learn the language and its practices.
There are several Rust crates (SDK) for gRPC. There&amp;rsquo;s no sanctioned SDK for Rust on grpc.io.
I chose stepancheg&amp;rsquo;s grpc-rust because it&amp;rsquo;s a pure Rust implementation (not built atop the C implementation).</description>
    </item>
    
    <item>
      <title>PyPi Transparency</title>
      <link>https://pretired.dazwilkin.com/posts/190926/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190926/</guid>
      <description>I&amp;rsquo;ve been noodling around with another Trillian personality.
Another in a theme that interests me in providing tamperproof logs for the packages in the popular package management registries.
The Golang team recently announced Go Module Mirror which is built atop Trillian. It seems to me that all the package registries (Go Modules, npm, Maven, NuGet etc.) would benefit from tamperproof logs hosted by a trusted 3rd-party.
As you may have guessed, PyPi Transparency is a log for PyPi packages.</description>
    </item>
    
    <item>
      <title>Run cAdvisor when using Docker Compose</title>
      <link>https://pretired.dazwilkin.com/posts/190925/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190925/</guid>
      <description>cAdvisor has long been a favorite monitoring tool of mine. I&amp;rsquo;m using Docker Compose for local testing and have begun including a cAdvisor in my docker-compose.yaml files.
cadvisor: restart: always image: google/cadvisor:${CADVISOR_VERSION} container_name: cadvisor # command: # - --prometheus_endpoint=&amp;#34;/metrics&amp;#34; # Default volumes: - &amp;#34;/:/rootfs:ro&amp;#34; - &amp;#34;/var/run:/var/run:rw&amp;#34; - &amp;#34;/sys:/sys:ro&amp;#34; - &amp;#34;/var/snap/docker/current:/var/lib/docker:ro&amp;#34; #- &amp;#34;/var/lib/docker/:/var/lib/docker:ro&amp;#34; expose: - &amp;#34;8080&amp;#34; ports: - 8080:8080 I&amp;rsquo;d not realized until recently, that cAdvisor also surfaces a Prometheus metrics endpoint and so, if you do follow this path and you&amp;rsquo;re also using Prometheus, don&amp;rsquo;t forget to add cAdvisor to your Prometheus targets.</description>
    </item>
    
    <item>
      <title>Kubernetes Engine and Free Tier</title>
      <link>https://pretired.dazwilkin.com/posts/190924/</link>
      <pubDate>Tue, 24 Sep 2019 09:40:14 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190924/</guid>
      <description>Google Cloud Platform Free Tier appears (please verify this for yourself) to provide the ability to run a(n admittedly miniscule) Kubernetes cluster for free. So, why do this? It provides a definitive Kubernetes (Engine) experience on Google Cloud Platform that you may use for learning and testing.
Kubernetes Engine the master node(s) and the control plane are free.
Kubernetes (i.e. Compute Engine) nodes potentially incur charges including for the VM runtime and any attached storage, snapshots etc.</description>
    </item>
    
    <item>
      <title>Cloud Functions Simple(st) HTTP Multi-host Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/190918/</link>
      <pubDate>Wed, 18 Sep 2019 12:45:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190918/</guid>
      <description>Tweaked yesterday&amp;rsquo;s solution so that it will randomly select one from several hosts with which it&amp;rsquo;s configured.
package proxy import ( &amp;#34;log&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/url&amp;#34; &amp;#34;os&amp;#34; &amp;#34;strings&amp;#34; &amp;#34;time&amp;#34; ) func robin() { hostsList := os.Getenv(&amp;#34;PROXY_HOST&amp;#34;) if hostsList == &amp;#34;&amp;#34; { log.Fatal(&amp;#34;&amp;#39;PROXY_HOST&amp;#39; environment variable should contain comma-separated list of hosts&amp;#34;) } // Comma-separated lists of hosts hosts := strings.Split(hostsList, &amp;#34;,&amp;#34;) urls := make([]*url.URL, len(hosts)) for i, host := range hosts { var origin = Endpoint{ Host: host, Port: os.</description>
    </item>
    
    <item>
      <title>Cloud Functions Simple(st) HTTP Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/190917/</link>
      <pubDate>Tue, 17 Sep 2019 12:41:02 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190917/</guid>
      <description>I&amp;rsquo;m investigating the use of LetsEncrypt for gRPC services. I found this straightforward post by Scott Devoid and am going to try this approach.
Before I can do that, I need to be able to publish services (make them Internet-accessible) and would like to try to continue to use GCP for free.
Some time ago, I wrote about using the excellent Microk8s on GCP. Using an f1-micro, I&amp;rsquo;m hoping (!) to stay within the Compute Engine free tier.</description>
    </item>
    
    <item>
      <title>Visual Studio Code: gopls and YAML</title>
      <link>https://pretired.dazwilkin.com/posts/190610/</link>
      <pubDate>Tue, 10 Sep 2019 10:23:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190610/</guid>
      <description>The Go team is developing a Language Server Protocol [LSP] implementation) called gopls. Visual Studio Code (and others) support LSP. Other languages (e.g. Python have LSP implementations too). I&amp;rsquo;ve been using gopls for some time. It works (mostly) very well and replaces multiple, indepedent tools with two (gopls and delve).
My Visual Studio Code settings that include gopls is:
&amp;#34;go.autocompleteUnimportedPackages&amp;#34;: true, &amp;#34;go.useLanguageServer&amp;#34;: true, &amp;#34;[go]&amp;#34;: { &amp;#34;editor.snippetSuggestions&amp;#34;: &amp;#34;none&amp;#34;, &amp;#34;editor.formatOnSave&amp;#34;: true, &amp;#34;editor.codeActionsOnSave&amp;#34;: { &amp;#34;source.</description>
    </item>
    
    <item>
      <title>pypi-transparency</title>
      <link>https://pretired.dazwilkin.com/posts/190907/</link>
      <pubDate>Sat, 07 Sep 2019 13:07:44 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190907/</guid>
      <description>The goal of pypi-transparency is very similar to the underlying motivation for the Golang team&amp;rsquo;s Checksum Database (also built with Trillian).
Even though, PyPi provides hashes of the content of packages it hosts, the developer must trust that PyPi&amp;rsquo;s data is consistent. One ambition with pypi-transparency is to provide a companion, tamperproof log of PyPi package files in order to provide a double-check of these hashes.
It is important to understand what this does (and does not) provide.</description>
    </item>
    
    <item>
      <title>Welcome</title>
      <link>https://pretired.dazwilkin.com/posts/190906/</link>
      <pubDate>Fri, 06 Sep 2019 13:54:49 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190906/</guid>
      <description>Now that I&amp;rsquo;ve (p)retired from Google, I&amp;rsquo;m starting this blog and will no longer post stories to Medium.
As I concluded my time at Google, I wrapped up work on a Trillian prototype. As it remains Google&amp;rsquo;s IP, I&amp;rsquo;m not permitted to discuss it here.
I&amp;rsquo;ve begun work on another Trillian prototype for Python package transparency, informally pypi-transparency.</description>
    </item>
    
  </channel>
</rss>
