<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>(p)retired</title>
    <link>https://pretired.dazwilkin.com/</link>
    <description>Recent content on (p)retired</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Jun 2020 00:00:00 -0700</lastBuildDate>
    
	<atom:link href="https://pretired.dazwilkin.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Golang Protobuf APIv2</title>
      <link>https://pretired.dazwilkin.com/posts/200630/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200630/</guid>
      <description>Google has a new API, APIv2 (google.golang.org/protobuf) superseding APIv1 (github.com/golang/protobuf). If your code is importing github.com/golang/protobuf, you&amp;rsquo;re using APIv2. Otherwise, you should consult with the docs because Google reimplemented APIv1 atop APIv2. One challenge this caused me, as someone who does not use protobufs and gRPC on a daily basis, is that gRPC (code-generation) is being removed from the (Golang) protoc-gen-go, the Golang plugin that generates gRPC service bindings.
 NOTE If your protoc-generated Golang sources include methods implementing the interface protoreflect.</description>
    </item>
    
    <item>
      <title>WASM Cloud Functions</title>
      <link>https://pretired.dazwilkin.com/posts/200617/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200617/</guid>
      <description>Following on from waPC &amp;amp; Protobufs and a question on Stack Overflow about Cloud Functions, I was compelled to try running WASM on Cloud Functions no JavaScript.
I wanted to reuse the WASM waPC functions that I&amp;rsquo;d written in Rust as described in the other post. Cloud Functions does not (yet!?) provide a Rust runtime and so I&amp;rsquo;m using the waPC Host for Go in this example.
It works!
PARAMS=$(printf &amp;#39;{&amp;#34;a&amp;#34;:{&amp;#34;real&amp;#34;:39,&amp;#34;imag&amp;#34;:3},&amp;#34;b&amp;#34;:{&amp;#34;real&amp;#34;:39,&amp;#34;imag&amp;#34;:3}}&amp;#39; | base64) TOKEN=$(gcloud auth print-identity-token) echo &amp;#34;{ \&amp;#34;filename\&amp;#34;:\&amp;#34;complex.</description>
    </item>
    
    <item>
      <title>waPC &amp; Protobufs</title>
      <link>https://pretired.dazwilkin.com/posts/200612/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200612/</guid>
      <description>I&amp;rsquo;m hacking around with a solution that combines WASM and Google Trillian.
Ultimately, I&amp;rsquo;d like to be able to ship WASM (binaries) to a Trillian personality and then invoke (exported) functions on them. Some this was borne from the interesting exploration of Krustlet and its application of wascc.
I&amp;rsquo;m still booting into WASM but it&amp;rsquo;s a very interesting technology that has most interesting potential outside the browser. Some folks have been trailblazing the technology and I have been reading Kevin Hoffman&amp;rsquo;s medium and wascc (nee waxosuit) work.</description>
    </item>
    
    <item>
      <title>Google Container Registry w/ OCI</title>
      <link>https://pretired.dazwilkin.com/posts/200508/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200508/</guid>
      <description>I&amp;rsquo;ve been spending some time this week with Krustlet.
I&amp;rsquo;m working on documenting how to run Krustlet(s) alongside GKE. I&amp;rsquo;ve been running a Krustlet with MicroK8s.
The Krustlet demos reference WASM assemblines stored in Azure Container Registry as OCI containers. Google Container Registry supports OCI format and so I tried (successfully) using GCR instead of AZR.
There may be an easier approach but this is how I got this working.</description>
    </item>
    
    <item>
      <title>Rust implementation of Crate Transparency using Google Trillian</title>
      <link>https://pretired.dazwilkin.com/posts/200429/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200429/</guid>
      <description>I&amp;rsquo;ve been hacking on a Rust-based transparent application for Google Trillian. As appears to be my fixation, this personality is for another package manager. This time, Rust&amp;rsquo;s Crates often found in crates.io which is Rust&amp;rsquo;s Package Registry. I discussed this project earlier this month Rust Crate Transparency &amp;amp;&amp;amp; Rust SDK for Google Trillian and and earlier approach for Python&amp;rsquo;s packages with pypi-transparency.
This time, of course, I&amp;rsquo;m using Rust. And, by way of a first for me, for the gRPC server implementation (aka &amp;ldquo;personality&amp;rdquo;).</description>
    </item>
    
    <item>
      <title>Golang Xiaomi Bluetooth Temperature|Humidity (LYWSD03MMC) 2nd Gen</title>
      <link>https://pretired.dazwilkin.com/posts/200417/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200417/</guid>
      <description>Well, this became more of an adventure that I&amp;rsquo;d originally wanted but, after learning some BLE and, with the help of others (Thanks Jonatha, JsBergbau), I&amp;rsquo;ve sample code that connects to 4 Xiaomi 2nd gen. Thermometers, subscribes to readings and publishes the data to MQTT. From there, I&amp;rsquo;m scraping it using Inuits MQTTGateway into Prometheus.
Repo: https://github.com/DazWilkin/gomijia2
Thanks|Credit:  Jonathan McDowell for gomijia and help JsBergbau for help  Background I&amp;rsquo;ve been playing around with ESPHome and blogged around my very positive experience ESPHome, MQTT, Prometheus and almost Cloud IoT.</description>
    </item>
    
    <item>
      <title>Rust Crate Transparency &amp;&amp; Rust SDK for Google Trillian</title>
      <link>https://pretired.dazwilkin.com/posts/200403/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200403/</guid>
      <description>I&amp;rsquo;m noodling the utility of a Transparency solution for Rust Crates. When developers push crates to Cargo, a bunch of metadata is associated with the crate. E.g. protobuf. As with Golang Modules, Python packages on PyPi etc., there appears to be utility in making tamperproof recordings of these publications. Then, other developers may confirm that a crate pulled from cates.io is highly unlikely to have been changed.
On Linux, Cargo stores downloaded crates under ${HOME}/.</description>
    </item>
    
    <item>
      <title>Google Trillian on Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/200326/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200326/</guid>
      <description>I&amp;rsquo;ve written previously (Google Trillian for Noobs) about Google&amp;rsquo;s interesting project Trillian and about some of the &amp;ldquo;personalities&amp;rdquo; (e.g. PyPi Transparency) that I&amp;rsquo;ve build using it.
Having gone slight cra-cra on Cloud Run and gRPC this week with Golang gRPC Cloud Run and gRPC, Cloud Run &amp;amp; Endpoints, I thought it&amp;rsquo;d be fun to deploy Trillian and a personality to Cloud Run.
It mostly (!) works :-)
At the end of the post, I&amp;rsquo;ve summarized creating a Cloud SQL instance to host the Trillian data(base).</description>
    </item>
    
    <item>
      <title>gRPC, Cloud Run &amp; Endpoints</title>
      <link>https://pretired.dazwilkin.com/posts/200325/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200325/</guid>
      <description>&amp;lt;3 Google but there&amp;rsquo;s quite often an assumption that we&amp;rsquo;re all sitting around the engineering table and, of course, we&amp;rsquo;re not.
Cloud Endpoints is a powerful offering but &amp;ndash; IMO &amp;ndash; it&amp;rsquo;s super confusing to understand and complex to deploy.
If you&amp;rsquo;re familiar with the motivations behind service meshes (e.g. Istio), Cloud Endpoints fits in a similar niche (&amp;ldquo;neesh&amp;rdquo; or &amp;ldquo;nitch&amp;rdquo;?). The underlying ambition is that, developers can take existing code and by adding a proxy (or sidecar), general-purpose abstractions, security, logging etc.</description>
    </item>
    
    <item>
      <title>Golang gRPC Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/200320/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200320/</guid>
      <description>Update: 2020-03-24: Since writing this post, I&amp;rsquo;ve contributed Golang and Rust samples to Google&amp;rsquo;s project. I recommend you start there.
 Google explained how to run gRPC servers with Cloud Run. The examples are good but only Python and Node.JS:
 gRPC comes to Cloud Run gRPC in Google Cloud Run  Missing Golang&amp;hellip;. until now ;-)
I had problems with 1.14 and so I&amp;rsquo;m using 1.13.
Project structure I&amp;rsquo;ll tidy up my repo but the code may be found:</description>
    </item>
    
    <item>
      <title>OriginStamp Rust SDK Example</title>
      <link>https://pretired.dazwilkin.com/posts/200312/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200312/</guid>
      <description>I wrote recently describing Python and Golang clients for OriginStamp based on OriginStamp&amp;rsquo;s API&amp;rsquo;s swagger spec. As a way to pursue learning rust, I&amp;rsquo;ve been forcing myself to write examples using rust. I&amp;rsquo;m honestly finding learning rust tough going and think I&amp;rsquo;m probably better to revert to the &amp;ldquo;Learning Rust&amp;rdquo; tutorials.
That said, herewith an explanation of building a rust client using an OpenAPI (!) generated SDK from OriginStamp&amp;rsquo;s swagger spec.</description>
    </item>
    
    <item>
      <title>Google&#39;s New Golang SDK for Protobuf</title>
      <link>https://pretired.dazwilkin.com/posts/200310/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200310/</guid>
      <description>Google has released a new Golang SDK for protobuf. In the [announcement], a useful tool to redact properties is described. If like me, this is somewhat novel to you, here&amp;rsquo;s a mashup using Google&amp;rsquo;s Protocol Buffer Basics w/ redaction.
To be very clear, as it&amp;rsquo;s an important distinction:
   Version Repo Docs     v2 google.golang.org/protobuf Docs   v1 github.com/golang/protobuf Docs    Project Here&amp;rsquo;s my project structure:</description>
    </item>
    
    <item>
      <title>ESPHome, MQTT, Prometheus and almost Cloud IoT</title>
      <link>https://pretired.dazwilkin.com/posts/200227/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200227/</guid>
      <description>ESPHome is a very interesting project. I&amp;rsquo;d not heard of it until this week and am surprised that it isn&amp;rsquo;t more newsworthy.
I&amp;rsquo;m always tinkering with IoT stuff, have a couple of Wemos D1 ESP8266s. They are brought out occasionally for learning. I&amp;rsquo;ve been using them this week with ESPHome. I&amp;rsquo;m looking to buy some Xiaomi BLE temperature sensors and thinking I could read the temperatures from these using the ESPs (thanks to ESPHome) and publish the data to MQTT.</description>
    </item>
    
    <item>
      <title>OriginStamp: Verifying Proofs</title>
      <link>https://pretired.dazwilkin.com/posts/200226/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200226/</guid>
      <description>Recently, I wrote about some initial adventures with OriginStamp
Using OriginStamp&amp;rsquo;s UI or API, submitting a hash results in transactions being submitted to Bitcoin, Ethereum and a German newspaper.
Using the API, it&amp;rsquo;s possible to query OriginStamp&amp;rsquo;s service for a proof. This post explains how to verify such a proof.
The diligent reader among you (Hey Mom!) will recall that I submitted a hash for the message:
Frederik Jack is a bubbly Border Collie The SHA-256 hash of this message is:</description>
    </item>
    
    <item>
      <title>FreeTSA &amp; Digitorus&#39; Timestamp SDK</title>
      <link>https://pretired.dazwilkin.com/posts/200219/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200219/</guid>
      <description>I wrote recently about some exploration of Timestamping with OriginStamp. Since writing that post, I had some supportive feedback from the helpful folks at OriginStamp and plan to continue exploring that solution.
Meanwhile, OriginStamp exposed me to timestamping and trusted timestamping and I discovered freeTSA.org.
What&amp;rsquo;s the point? These services provide authoritative proof of the existence of a digital asset before some point in time; OriginStamp provides a richer service and uses multiple timestamp authorities including Bitcoin, Ethereum and rather interestingly a German Newspaper&amp;rsquo;s Trusted Timestamp.</description>
    </item>
    
    <item>
      <title>OriginStamp Python|Golang SDK Examples</title>
      <link>https://pretired.dazwilkin.com/posts/200217/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200217/</guid>
      <description>A friend mentioned OriginStamp to me.
NB There are 2 sites: originstamp.com and originstamp.org.
It&amp;rsquo;s an interesting project.
It&amp;rsquo;s a solution for providing auditable proof that you had a(ccess to) some digital thing before a certain date. OriginStamp provides user-|developer-friendly means to submit files|hashes (of your content) and have these bundled into transactions that are submitted to e.g. bitcoin.
I won&amp;rsquo;t attempt to duplicate the narrative here, review OriginStamp&amp;rsquo;s site and some of its content.</description>
    </item>
    
    <item>
      <title>Accessing GCR repos from Kubernetes</title>
      <link>https://pretired.dazwilkin.com/posts/200207/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200207/</guid>
      <description>Until today, I&amp;rsquo;d not accessed a Google Container Registry repo from a non-GKE Kubernetes deployment.
It turns out that it&amp;rsquo;s pretty well-documented (link) but, here&amp;rsquo;s an end-end example.
Assuming:
BILLING=[[YOUR-BILLING]] PROJECT=[[YOUR-PROJECT]] SERVER=&amp;#34;us.gcr.io&amp;#34; If not already:
gcloud projects create {$PROJECT} gcloud beta billing projects link ${PROJECT} \ --billing-account=${BILLING} gcloud services enable containerregistry.googleapis.com \ --project=${PROJECT} Container Registry IMAGE=&amp;#34;busybox&amp;#34; # Or ... docker pull ${IMAGE} docker tag \  ${IMAGE} \  ${SERVER}/${PROJECT}/${IMAGE} docker push ${SERVER}/${PROJECT}/${IMAGE} gcloud container images list-tags ${SERVER}/${PROJECT}/${IMAGE} Service Account Create a service account that&amp;rsquo;s permitted to download (read-only) images from this project&amp;rsquo;s registry</description>
    </item>
    
    <item>
      <title>Cloud Build wishlist: Mountable Golang Modules Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/200206/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200206/</guid>
      <description>I think it would be valuable if Google were to provide volumes in Cloud Build of package registries (e.g. Go Modules; PyPi; Maven; NPM etc.).
Google provides a mirror of a subset of Docker Hub. This confers several benefits: Google&amp;rsquo;s imprimatur; speed (latency); bandwidth; and convenience.
The same benefits would apply to package registries.
In the meantime, there&amp;rsquo;s a hacky way to gain some of the benefits of these when using Cloud Build.</description>
    </item>
    
    <item>
      <title>Setting up a GCE Instance as an Inlets Exit Node</title>
      <link>https://pretired.dazwilkin.com/posts/200122/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200122/</guid>
      <description>The prolific Alex Ellis has a new project, Inlets.
Here&amp;rsquo;s a quick tutorial using Google Compute Platform&amp;rsquo;s (GCP) Compute Engine (GCE).
NB I&amp;rsquo;m using one of Google&amp;rsquo;s &amp;ldquo;Always free&amp;rdquo; f1-micro instances but you may still pay for network *gress and storage
Assumptions I&amp;rsquo;m assuming you&amp;rsquo;ve a Google account, have used GCP and have a billing account established, i.e. the following returns at least one billing account:
gcloud beta billing accounts list If you&amp;rsquo;ve only one billing account and it&amp;rsquo;s the one you wish to use, then you can:</description>
    </item>
    
    <item>
      <title>Trendnet TEW-812DRU and DD-WRT</title>
      <link>https://pretired.dazwilkin.com/posts/200113/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200113/</guid>
      <description>The FBI Portland published an interesting advisory with several, sensible recommendations including firewalling IoT devices from other devices on a home network. I decided to deploy a redundant Trendnet TEW-812DRU version 2.0 for this purpose.
Caveat Developer: Before I go further, I don&amp;rsquo;t recommend installing DD-WRT on a Trendnet TEW-812DRU unless you&amp;rsquo;re willing to brick the device irrecoverably.
I read the DD-WRT instructions several times (&amp;ldquo;peacock thread&amp;rdquo;,router database &amp;ndash; do not use v3.</description>
    </item>
    
    <item>
      <title>Google Fit</title>
      <link>https://pretired.dazwilkin.com/posts/200110/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200110/</guid>
      <description>I&amp;rsquo;ve spent a few days exploring [Google Fit SDK] as I try to wean myself from my obsession with metrics (of all forms). A quick Googling got me to Robert&amp;rsquo;s Exporter Google Fit Daily Steps, Weight and Distance to a Google Sheet. This works and is probably where I should have stopped&amp;hellip; avoiding the rabbit hole that I&amp;rsquo;ve been down&amp;hellip;
I threw together a simple Golang implementation of the SDK using Google&amp;rsquo;s Golang API Client Library.</description>
    </item>
    
    <item>
      <title>Google Home Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/200107/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200107/</guid>
      <description>I&amp;rsquo;m obsessing over Prometheus exporters. First came Linode Exporter, then GCP Exporter and, on Sunday, I stumbled upon a reverse-engineered API for Google Home devices and so wrote a very basic Google Home SDK and a similarly basic Google Home Exporter:
The SDK only implements /setup/eureka_info and then only some of the returned properties. There&amp;rsquo;s not a lot of metric-like data to use besides SignalLevel (signal_level) and NoiseLevel (noise_level). I&amp;rsquo;m not clear on the meaning of some of the properties.</description>
    </item>
    
    <item>
      <title>Adventures around BPF</title>
      <link>https://pretired.dazwilkin.com/posts/191230/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191230/</guid>
      <description>I think (!?) this interesting learning experience started with Envoy Go Extensions.
IIUC, Cilium contributed this mechanism (Envoy Go Extensions) by which it&amp;rsquo;s possible to extend Envoy using Golang. The documentation references BPF. Cilium and BNF were both unfamiliar technologies to me and so began my learning. This part of the journey concludes with Weave Scope.
I learned that Cilium is a CNI implementation that may be used with Kubernetes. GKE defaults (but is not limited to) to Google&amp;rsquo;s own CNI implementation (link).</description>
    </item>
    
    <item>
      <title>Google Cloud Platform (GCP) Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191220/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191220/</guid>
      <description>Earlier this week I discussed a Linode Prometheus Exporter.
I added metrics for Digital Ocean&amp;rsquo;s Managed Kubernetes service to @metalmatze&amp;rsquo;s Digital Ocean Exporter.
This left, metrics for Google Cloud Platform (GCP) which has, for many years, been my primary cloud platform. So, today I wrote Prometheus Exporter for Google Cloud Platform.
All 3 of these exporters follow the template laid down by @metalmatze and, because each of these services has a well-written Golang SDK, it&amp;rsquo;s straightforward to implement an exporter for each of them.</description>
    </item>
    
    <item>
      <title>Prometheus AlertManager</title>
      <link>https://pretired.dazwilkin.com/posts/191219/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191219/</guid>
      <description>Yesterday I discussed a Linode Prometheus Exporter and tantalized use of Prometheus AlertManager.
Success:
Configure The process is straightforward although I found the Prometheus (config) documentation slightly unwieldy to navigate :-(
The overall process is documented.
Here are the steps I took:
 Configure Prometheus Configure AlertManager Revise Docker Compose  Configure Prometheus Added the following to prometheus.yml:
rule_files: - &amp;#34;/etc/alertmanager/rules/linode.yml&amp;#34; alerting: alertmanagers: - scheme: http static_configs: - targets: - &amp;#34;alertmanager:9093&amp;#34; Rules must be defined in separate rules files.</description>
    </item>
    
    <item>
      <title>Linode Prometheus Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191218/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191218/</guid>
      <description>I enjoy using Prometheus and have toyed around with it for some time particularly in combination with Kubernetes. I signed up with Linode [referral] compelled by the addition of a managed Kubernetes service called Linode Kubernetes Engine (LKE). I have an anxiety that I&amp;rsquo;ll inadvertently leave resources running (unused) on a cloud platform. Instead of refreshing the relevant billing page, it struck me that Prometheus may (not yet proven) help.</description>
    </item>
    
    <item>
      <title>NGINX Ingress</title>
      <link>https://pretired.dazwilkin.com/posts/191211/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191211/</guid>
      <description>I&amp;rsquo;ve written a couple of deployment options (Google Compute Engine; Kubernetes) for an open-source project. The Kubernetes deployment provides NodePort and (TCP) LoadBalancer options and I&amp;rsquo;ve been trying (unsuccessfully) to add HTTPS Load-balancing.
I should (!) try to deploy to Google Kubernetes Engine (GKE) but I&amp;rsquo;ve been using microk8s, Digital Ocean Managed Kubernetes and the Linode LKE Beta. Each of these requires an implementation of Ingress controller. For GKE, GCP&amp;rsquo;s HTTP/S Load-balancer (GCLB) is used.</description>
    </item>
    
    <item>
      <title>PyPi Transparency Client (Rust)</title>
      <link>https://pretired.dazwilkin.com/posts/190930/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190930/</guid>
      <description>I&amp;rsquo;ve finally being able to hack my way through to a working Rust gRPC client (for PyPi Transparency).
It&amp;rsquo;s not very good: poorly structured, hacky etc. but it serves the purpose of giving me a foothold into Rust development so that I can evolve it as I learn the language and its practices.
There are several Rust crates (SDK) for gRPC. There&amp;rsquo;s no sanctioned SDK for Rust on grpc.io.
I chose stepancheg&amp;rsquo;s grpc-rust because it&amp;rsquo;s a pure Rust implementation (not built atop the C implementation).</description>
    </item>
    
    <item>
      <title>PyPi Transparency</title>
      <link>https://pretired.dazwilkin.com/posts/190926/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190926/</guid>
      <description>I&amp;rsquo;ve been noodling around with another Trillian personality.
Another in a theme that interests me in providing tamperproof logs for the packages in the popular package management registries.
The Golang team recently announced Go Module Mirror which is built atop Trillian. It seems to me that all the package registries (Go Modules, npm, Maven, NuGet etc.) would benefit from tamperproof logs hosted by a trusted 3rd-party.
As you may have guessed, PyPi Transparency is a log for PyPi packages.</description>
    </item>
    
    <item>
      <title>Run cAdvisor when using Docker Compose</title>
      <link>https://pretired.dazwilkin.com/posts/190925/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190925/</guid>
      <description>cAdvisor has long been a favorite monitoring tool of mine. I&amp;rsquo;m using Docker Compose for local testing and have begun including a cAdvisor in my docker-compose.yaml files.
cadvisor: restart: always image: google/cadvisor:${CADVISOR_VERSION} container_name: cadvisor # command: # - --prometheus_endpoint=&amp;#34;/metrics&amp;#34; # Default volumes: - &amp;#34;/:/rootfs:ro&amp;#34; - &amp;#34;/var/run:/var/run:rw&amp;#34; - &amp;#34;/sys:/sys:ro&amp;#34; - &amp;#34;/var/snap/docker/current:/var/lib/docker:ro&amp;#34; #- &amp;#34;/var/lib/docker/:/var/lib/docker:ro&amp;#34; expose: - &amp;#34;8080&amp;#34; ports: - 8080:8080 I&amp;rsquo;d not realized until recently, that cAdvisor also surfaces a Prometheus metrics endpoint and so, if you do follow this path and you&amp;rsquo;re also using Prometheus, don&amp;rsquo;t forget to add cAdvisor to your Prometheus targets.</description>
    </item>
    
    <item>
      <title>Kubernetes Engine and Free Tier</title>
      <link>https://pretired.dazwilkin.com/posts/190924/</link>
      <pubDate>Tue, 24 Sep 2019 09:40:14 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190924/</guid>
      <description>Google Cloud Platform Free Tier appears (please verify this for yourself) to provide the ability to run a(n admittedly miniscule) Kubernetes cluster for free. So, why do this? It provides a definitive Kubernetes (Engine) experience on Google Cloud Platform that you may use for learning and testing.
Kubernetes Engine the master node(s) and the control plane are free.
Kubernetes (i.e. Compute Engine) nodes potentially incur charges including for the VM runtime and any attached storage, snapshots etc.</description>
    </item>
    
    <item>
      <title>Cloud Functions Simple(st) HTTP Multi-host Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/190918/</link>
      <pubDate>Wed, 18 Sep 2019 12:45:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190918/</guid>
      <description>Tweaked yesterday&amp;rsquo;s solution so that it will randomly select one from several hosts with which it&amp;rsquo;s configured.
package proxy import ( &amp;#34;log&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/url&amp;#34; &amp;#34;os&amp;#34; &amp;#34;strings&amp;#34; &amp;#34;time&amp;#34; ) func robin() { hostsList := os.Getenv(&amp;#34;PROXY_HOST&amp;#34;) if hostsList == &amp;#34;&amp;#34; { log.Fatal(&amp;#34;&amp;#39;PROXY_HOST&amp;#39; environment variable should contain comma-separated list of hosts&amp;#34;) } // Comma-separated lists of hosts  hosts := strings.Split(hostsList, &amp;#34;,&amp;#34;) urls := make([]*url.URL, len(hosts)) for i, host := range hosts { var origin = Endpoint{ Host: host, Port: os.</description>
    </item>
    
    <item>
      <title>Cloud Functions Simple(st) HTTP Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/190917/</link>
      <pubDate>Tue, 17 Sep 2019 12:41:02 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190917/</guid>
      <description>I&amp;rsquo;m investigating the use of LetsEncrypt for gRPC services. I found this straightforward post by Scott Devoid and am going to try this approach.
Before I can do that, I need to be able to publish services (make them Internet-accessible) and would like to try to continue to use GCP for free.
Some time ago, I wrote about using the excellent Microk8s on GCP. Using an f1-micro, I&amp;rsquo;m hoping (!) to stay within the Compute Engine free tier.</description>
    </item>
    
    <item>
      <title>Visual Studio Code: gopls and YAML</title>
      <link>https://pretired.dazwilkin.com/posts/190610/</link>
      <pubDate>Tue, 10 Sep 2019 10:23:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190610/</guid>
      <description>The Go team is developing a Language Server Protocol [LSP] implementation) called gopls. Visual Studio Code (and others) support LSP. Other languages (e.g. Python have LSP implementations too). I&amp;rsquo;ve been using gopls for some time. It works (mostly) very well and replaces multiple, indepedent tools with two (gopls and delve).
My Visual Studio Code settings that include gopls is:
&amp;#34;go.autocompleteUnimportedPackages&amp;#34;: true, &amp;#34;go.useLanguageServer&amp;#34;: true, &amp;#34;[go]&amp;#34;: { &amp;#34;editor.snippetSuggestions&amp;#34;: &amp;#34;none&amp;#34;, &amp;#34;editor.formatOnSave&amp;#34;: true, &amp;#34;editor.codeActionsOnSave&amp;#34;: { &amp;#34;source.</description>
    </item>
    
    <item>
      <title>pypi-transparency</title>
      <link>https://pretired.dazwilkin.com/posts/190907/</link>
      <pubDate>Sat, 07 Sep 2019 13:07:44 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190907/</guid>
      <description>The goal of pypi-transparency is very similar to the underlying motivation for the Golang team&amp;rsquo;s Checksum Database (also built with Trillian).
Even though, PyPi provides hashes of the content of packages it hosts, the developer must trust that PyPi&amp;rsquo;s data is consistent. One ambition with pypi-transparency is to provide a companion, tamperproof log of PyPi package files in order to provide a double-check of these hashes.
It is important to understand what this does (and does not) provide.</description>
    </item>
    
    <item>
      <title>Welcome</title>
      <link>https://pretired.dazwilkin.com/posts/190906/</link>
      <pubDate>Fri, 06 Sep 2019 13:54:49 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190906/</guid>
      <description>Now that I&amp;rsquo;ve (p)retired from Google, I&amp;rsquo;m starting this blog and will no longer post stories to Medium.
As I concluded my time at Google, I wrapped up work on a Trillian prototype. As it remains Google&amp;rsquo;s IP, I&amp;rsquo;m not permitted to discuss it here.
I&amp;rsquo;ve begun work on another Trillian prototype for Python package transparency, informally pypi-transparency.</description>
    </item>
    
  </channel>
</rss>