<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Golang on (p)retired</title>
    <link>https://pretired.dazwilkin.com/tags/golang/</link>
    <description>Recent content in Golang on (p)retired</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Mar 2020 00:00:00 -0800</lastBuildDate>
    
	<atom:link href="https://pretired.dazwilkin.com/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Golang gRPC Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/200320/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200320/</guid>
      <description>Update: 2020-03-24: Since writing this post, I&amp;rsquo;ve contributed Golang and Rust samples to Google&amp;rsquo;s project. I recommend you start there.
 Google explained how to run gRPC servers with Cloud Run. The examples are good but only Python and Node.JS:
 gRPC comes to Cloud Run gRPC in Google Cloud Run  Missing Golang&amp;hellip;. until now ;-)
I had problems with 1.14 and so I&amp;rsquo;m using 1.13.
Project structure I&amp;rsquo;ll tidy up my repo but the code may be found:</description>
    </item>
    
    <item>
      <title>Google&#39;s New Golang SDK for Protobuf</title>
      <link>https://pretired.dazwilkin.com/posts/200310/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200310/</guid>
      <description>Google has released a new Golang SDK for protobuf. In the [announcement], a useful tool to redact properties is described. If like me, this is somewhat novel to you, here&amp;rsquo;s a mashup using Google&amp;rsquo;s Protocol Buffer Basics w/ redaction.
To be very clear, as it&amp;rsquo;s an important distinction:
   Version Repo Docs     v2 google.golang.org/protobuf Docs   v1 github.com/golang/protobuf Docs    Project Here&amp;rsquo;s my project structure:</description>
    </item>
    
    <item>
      <title>OriginStamp: Verifying Proofs</title>
      <link>https://pretired.dazwilkin.com/posts/200226/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200226/</guid>
      <description>Recently, I wrote about some initial adventures with OriginStamp
Using OriginStamp&amp;rsquo;s UI or API, submitting a hash results in transactions being submitted to Bitcoin, Ethereum and a German newspaper.
Using the API, it&amp;rsquo;s possible to query OriginStamp&amp;rsquo;s service for a proof. This post explains how to verify such a proof.
The diligent reader among you (Hey Mom!) will recall that I submitted a hash for the message:
Frederik Jack is a bubbly Border Collie The SHA-256 hash of this message is:</description>
    </item>
    
    <item>
      <title>FreeTSA &amp; Digitorus&#39; Timestamp SDK</title>
      <link>https://pretired.dazwilkin.com/posts/200219/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200219/</guid>
      <description>I wrote recently about some exploration of Timestamping with OriginStamp. Since writing that post, I had some supportive feedback from the helpful folks at OriginStamp and plan to continue exploring that solution.
Meanwhile, OriginStamp exposed me to timestamping and trusted timestamping and I discovered freeTSA.org.
What&amp;rsquo;s the point? These services provide authoritative proof of the existence of a digital asset before some point in time; OriginStamp provides a richer service and uses multiple timestamp authorities including Bitcoin, Ethereum and rather interestingly a German Newspaper&amp;rsquo;s Trusted Timestamp.</description>
    </item>
    
    <item>
      <title>OriginStamp Python|Golang SDK Examples</title>
      <link>https://pretired.dazwilkin.com/posts/200217/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200217/</guid>
      <description>A friend mentioned OriginStamp to me.
NB There are 2 sites: originstamp.com and originstamp.org.
It&amp;rsquo;s an interesting project.
It&amp;rsquo;s a solution for providing auditable proof that you had a(ccess to) some digital thing before a certain date. OriginStamp provides user-|developer-friendly means to submit files|hashes (of your content) and have these bundled into transactions that are submitted to e.g. bitcoin.
I won&amp;rsquo;t attempt to duplicate the narrative here, review OriginStamp&amp;rsquo;s site and some of its content.</description>
    </item>
    
    <item>
      <title>Cloud Build wishlist: Mountable Golang Modules Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/200206/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200206/</guid>
      <description>I think it would be valuable if Google were to provide volumes in Cloud Build of package registries (e.g. Go Modules; PyPi; Maven; NPM etc.).
Google provides a mirror of a subset of Docker Hub. This confers several benefits: Google&amp;rsquo;s imprimatur; speed (latency); bandwidth; and convenience.
The same benefits would apply to package registries.
In the meantime, there&amp;rsquo;s a hacky way to gain some of the benefits of these when using Cloud Build.</description>
    </item>
    
    <item>
      <title>Setting up a GCE Instance as an Inlets Exit Node</title>
      <link>https://pretired.dazwilkin.com/posts/200122/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200122/</guid>
      <description>The prolific Alex Ellis has a new project, Inlets.
Here&amp;rsquo;s a quick tutorial using Google Compute Platform&amp;rsquo;s (GCP) Compute Engine (GCE).
NB I&amp;rsquo;m using one of Google&amp;rsquo;s &amp;ldquo;Always free&amp;rdquo; f1-micro instances but you may still pay for network *gress and storage
Assumptions I&amp;rsquo;m assuming you&amp;rsquo;ve a Google account, have used GCP and have a billing account established, i.e. the following returns at least one billing account:
gcloud beta billing accounts list If you&amp;rsquo;ve only one billing account and it&amp;rsquo;s the one you wish to use, then you can:</description>
    </item>
    
    <item>
      <title>Google Fit</title>
      <link>https://pretired.dazwilkin.com/posts/200110/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200110/</guid>
      <description>I&amp;rsquo;ve spent a few days exploring [Google Fit SDK] as I try to wean myself from my obsession with metrics (of all forms). A quick Googling got me to Robert&amp;rsquo;s Exporter Google Fit Daily Steps, Weight and Distance to a Google Sheet. This works and is probably where I should have stopped&amp;hellip; avoiding the rabbit hole that I&amp;rsquo;ve been down&amp;hellip;
I threw together a simple Golang implementation of the SDK using Google&amp;rsquo;s Golang API Client Library.</description>
    </item>
    
    <item>
      <title>Google Home Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/200107/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200107/</guid>
      <description>I&amp;rsquo;m obsessing over Prometheus exporters. First came Linode Exporter, then GCP Exporter and, on Sunday, I stumbled upon a reverse-engineered API for Google Home devices and so wrote a very basic Google Home SDK and a similarly basic Google Home Exporter:
The SDK only implements /setup/eureka_info and then only some of the returned properties. There&amp;rsquo;s not a lot of metric-like data to use besides SignalLevel (signal_level) and NoiseLevel (noise_level). I&amp;rsquo;m not clear on the meaning of some of the properties.</description>
    </item>
    
    <item>
      <title>Google Cloud Platform (GCP) Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191220/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191220/</guid>
      <description>Earlier this week I discussed a Linode Prometheus Exporter.
I added metrics for Digital Ocean&amp;rsquo;s Managed Kubernetes service to @metalmatze&amp;lsquo;s Digital Ocean Exporter.
This left, metrics for Google Cloud Platform (GCP) which has, for many years, been my primary cloud platform. So, today I wrote Prometheus Exporter for Google Cloud Platform.
All 3 of these exporters follow the template laid down by @metalmatze and, because each of these services has a well-written Golang SDK, it&amp;rsquo;s straightforward to implement an exporter for each of them.</description>
    </item>
    
    <item>
      <title>Linode Prometheus Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191218/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191218/</guid>
      <description>I enjoy using Prometheus and have toyed around with it for some time particularly in combination with Kubernetes. I signed up with Linode [referral] compelled by the addition of a managed Kubernetes service called Linode Kubernetes Engine (LKE). I have an anxiety that I&amp;rsquo;ll inadvertently leave resources running (unused) on a cloud platform. Instead of refreshing the relevant billing page, it struck me that Prometheus may (not yet proven) help.</description>
    </item>
    
  </channel>
</rss>