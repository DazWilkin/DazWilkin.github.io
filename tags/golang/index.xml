<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Golang on (p)retired</title>
    <link>https://pretired.dazwilkin.com/tags/golang/</link>
    <description>Recent content in Golang on (p)retired</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Jun 2020 00:00:00 -0700</lastBuildDate>
    
	<atom:link href="https://pretired.dazwilkin.com/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Golang Protobuf APIv2</title>
      <link>https://pretired.dazwilkin.com/posts/200630/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200630/</guid>
      <description>Google has a new API, APIv2 (google.golang.org/protobuf) superseding APIv1 (github.com/golang/protobuf). If your code is importing github.com/golang/protobuf, you&amp;rsquo;re using APIv2. Otherwise, you should consult with the docs because Google reimplemented APIv1 atop APIv2. One challenge this caused me, as someone who does not use protobufs and gRPC on a daily basis, is that gRPC (code-generation) is being removed from the (Golang) protoc-gen-go, the Golang plugin that generates gRPC service bindings.
 NOTE If your protoc-generated Golang sources include methods implementing the interface protoreflect.</description>
    </item>
    
    <item>
      <title>Golang Xiaomi Bluetooth Temperature|Humidity (LYWSD03MMC) 2nd Gen</title>
      <link>https://pretired.dazwilkin.com/posts/200417/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200417/</guid>
      <description>Well, this became more of an adventure that I&amp;rsquo;d originally wanted but, after learning some BLE and, with the help of others (Thanks Jonatha, JsBergbau), I&amp;rsquo;ve sample code that connects to 4 Xiaomi 2nd gen. Thermometers, subscribes to readings and publishes the data to MQTT. From there, I&amp;rsquo;m scraping it using Inuits MQTTGateway into Prometheus.
Repo: https://github.com/DazWilkin/gomijia2
Thanks|Credit:  Jonathan McDowell for gomijia and help JsBergbau for help  Background I&amp;rsquo;ve been playing around with ESPHome and blogged around my very positive experience ESPHome, MQTT, Prometheus and almost Cloud IoT.</description>
    </item>
    
    <item>
      <title>gRPC, Cloud Run &amp; Endpoints</title>
      <link>https://pretired.dazwilkin.com/posts/200325/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200325/</guid>
      <description>&amp;lt;3 Google but there&amp;rsquo;s quite often an assumption that we&amp;rsquo;re all sitting around the engineering table and, of course, we&amp;rsquo;re not.
Cloud Endpoints is a powerful offering but &amp;ndash; IMO &amp;ndash; it&amp;rsquo;s super confusing to understand and complex to deploy.
If you&amp;rsquo;re familiar with the motivations behind service meshes (e.g. Istio), Cloud Endpoints fits in a similar niche (&amp;ldquo;neesh&amp;rdquo; or &amp;ldquo;nitch&amp;rdquo;?). The underlying ambition is that, developers can take existing code and by adding a proxy (or sidecar), general-purpose abstractions, security, logging etc.</description>
    </item>
    
    <item>
      <title>Golang gRPC Cloud Run</title>
      <link>https://pretired.dazwilkin.com/posts/200320/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200320/</guid>
      <description>Update: 2020-03-24: Since writing this post, I&amp;rsquo;ve contributed Golang and Rust samples to Google&amp;rsquo;s project. I recommend you start there.
 Google explained how to run gRPC servers with Cloud Run. The examples are good but only Python and Node.JS:
 gRPC comes to Cloud Run gRPC in Google Cloud Run  Missing Golang&amp;hellip;. until now ;-)
I had problems with 1.14 and so I&amp;rsquo;m using 1.13.
Project structure I&amp;rsquo;ll tidy up my repo but the code may be found:</description>
    </item>
    
    <item>
      <title>Google&#39;s New Golang SDK for Protobuf</title>
      <link>https://pretired.dazwilkin.com/posts/200310/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200310/</guid>
      <description>Google has released a new Golang SDK for protobuf. In the [announcement], a useful tool to redact properties is described. If like me, this is somewhat novel to you, here&amp;rsquo;s a mashup using Google&amp;rsquo;s Protocol Buffer Basics w/ redaction.
To be very clear, as it&amp;rsquo;s an important distinction:
   Version Repo Docs     v2 google.golang.org/protobuf Docs   v1 github.com/golang/protobuf Docs    Project Here&amp;rsquo;s my project structure:</description>
    </item>
    
    <item>
      <title>OriginStamp: Verifying Proofs</title>
      <link>https://pretired.dazwilkin.com/posts/200226/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200226/</guid>
      <description>Recently, I wrote about some initial adventures with OriginStamp
Using OriginStamp&amp;rsquo;s UI or API, submitting a hash results in transactions being submitted to Bitcoin, Ethereum and a German newspaper.
Using the API, it&amp;rsquo;s possible to query OriginStamp&amp;rsquo;s service for a proof. This post explains how to verify such a proof.
The diligent reader among you (Hey Mom!) will recall that I submitted a hash for the message:
Frederik Jack is a bubbly Border Collie The SHA-256 hash of this message is:</description>
    </item>
    
    <item>
      <title>FreeTSA &amp; Digitorus&#39; Timestamp SDK</title>
      <link>https://pretired.dazwilkin.com/posts/200219/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200219/</guid>
      <description>I wrote recently about some exploration of Timestamping with OriginStamp. Since writing that post, I had some supportive feedback from the helpful folks at OriginStamp and plan to continue exploring that solution.
Meanwhile, OriginStamp exposed me to timestamping and trusted timestamping and I discovered freeTSA.org.
What&amp;rsquo;s the point? These services provide authoritative proof of the existence of a digital asset before some point in time; OriginStamp provides a richer service and uses multiple timestamp authorities including Bitcoin, Ethereum and rather interestingly a German Newspaper&amp;rsquo;s Trusted Timestamp.</description>
    </item>
    
    <item>
      <title>OriginStamp Python|Golang SDK Examples</title>
      <link>https://pretired.dazwilkin.com/posts/200217/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200217/</guid>
      <description>A friend mentioned OriginStamp to me.
NB There are 2 sites: originstamp.com and originstamp.org.
It&amp;rsquo;s an interesting project.
It&amp;rsquo;s a solution for providing auditable proof that you had a(ccess to) some digital thing before a certain date. OriginStamp provides user-|developer-friendly means to submit files|hashes (of your content) and have these bundled into transactions that are submitted to e.g. bitcoin.
I won&amp;rsquo;t attempt to duplicate the narrative here, review OriginStamp&amp;rsquo;s site and some of its content.</description>
    </item>
    
    <item>
      <title>Cloud Build wishlist: Mountable Golang Modules Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/200206/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200206/</guid>
      <description>I think it would be valuable if Google were to provide volumes in Cloud Build of package registries (e.g. Go Modules; PyPi; Maven; NPM etc.).
Google provides a mirror of a subset of Docker Hub. This confers several benefits: Google&amp;rsquo;s imprimatur; speed (latency); bandwidth; and convenience.
The same benefits would apply to package registries.
In the meantime, there&amp;rsquo;s a hacky way to gain some of the benefits of these when using Cloud Build.</description>
    </item>
    
    <item>
      <title>Setting up a GCE Instance as an Inlets Exit Node</title>
      <link>https://pretired.dazwilkin.com/posts/200122/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200122/</guid>
      <description>The prolific Alex Ellis has a new project, Inlets.
Here&amp;rsquo;s a quick tutorial using Google Compute Platform&amp;rsquo;s (GCP) Compute Engine (GCE).
NB I&amp;rsquo;m using one of Google&amp;rsquo;s &amp;ldquo;Always free&amp;rdquo; f1-micro instances but you may still pay for network *gress and storage
Assumptions I&amp;rsquo;m assuming you&amp;rsquo;ve a Google account, have used GCP and have a billing account established, i.e. the following returns at least one billing account:
gcloud beta billing accounts list If you&amp;rsquo;ve only one billing account and it&amp;rsquo;s the one you wish to use, then you can:</description>
    </item>
    
    <item>
      <title>Google Fit</title>
      <link>https://pretired.dazwilkin.com/posts/200110/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200110/</guid>
      <description>I&amp;rsquo;ve spent a few days exploring [Google Fit SDK] as I try to wean myself from my obsession with metrics (of all forms). A quick Googling got me to Robert&amp;rsquo;s Exporter Google Fit Daily Steps, Weight and Distance to a Google Sheet. This works and is probably where I should have stopped&amp;hellip; avoiding the rabbit hole that I&amp;rsquo;ve been down&amp;hellip;
I threw together a simple Golang implementation of the SDK using Google&amp;rsquo;s Golang API Client Library.</description>
    </item>
    
    <item>
      <title>Google Home Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/200107/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200107/</guid>
      <description>I&amp;rsquo;m obsessing over Prometheus exporters. First came Linode Exporter, then GCP Exporter and, on Sunday, I stumbled upon a reverse-engineered API for Google Home devices and so wrote a very basic Google Home SDK and a similarly basic Google Home Exporter:
The SDK only implements /setup/eureka_info and then only some of the returned properties. There&amp;rsquo;s not a lot of metric-like data to use besides SignalLevel (signal_level) and NoiseLevel (noise_level). I&amp;rsquo;m not clear on the meaning of some of the properties.</description>
    </item>
    
    <item>
      <title>Google Cloud Platform (GCP) Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191220/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191220/</guid>
      <description>Earlier this week I discussed a Linode Prometheus Exporter.
I added metrics for Digital Ocean&amp;rsquo;s Managed Kubernetes service to @metalmatze&amp;rsquo;s Digital Ocean Exporter.
This left, metrics for Google Cloud Platform (GCP) which has, for many years, been my primary cloud platform. So, today I wrote Prometheus Exporter for Google Cloud Platform.
All 3 of these exporters follow the template laid down by @metalmatze and, because each of these services has a well-written Golang SDK, it&amp;rsquo;s straightforward to implement an exporter for each of them.</description>
    </item>
    
    <item>
      <title>Linode Prometheus Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191218/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191218/</guid>
      <description>I enjoy using Prometheus and have toyed around with it for some time particularly in combination with Kubernetes. I signed up with Linode [referral] compelled by the addition of a managed Kubernetes service called Linode Kubernetes Engine (LKE). I have an anxiety that I&amp;rsquo;ll inadvertently leave resources running (unused) on a cloud platform. Instead of refreshing the relevant billing page, it struck me that Prometheus may (not yet proven) help.</description>
    </item>
    
    <item>
      <title>PyPi Transparency</title>
      <link>https://pretired.dazwilkin.com/posts/190926/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190926/</guid>
      <description>I&amp;rsquo;ve been noodling around with another Trillian personality.
Another in a theme that interests me in providing tamperproof logs for the packages in the popular package management registries.
The Golang team recently announced Go Module Mirror which is built atop Trillian. It seems to me that all the package registries (Go Modules, npm, Maven, NuGet etc.) would benefit from tamperproof logs hosted by a trusted 3rd-party.
As you may have guessed, PyPi Transparency is a log for PyPi packages.</description>
    </item>
    
    <item>
      <title>Cloud Functions Simple(st) HTTP Multi-host Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/190918/</link>
      <pubDate>Wed, 18 Sep 2019 12:45:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190918/</guid>
      <description>Tweaked yesterday&amp;rsquo;s solution so that it will randomly select one from several hosts with which it&amp;rsquo;s configured.
package proxy import ( &amp;#34;log&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/url&amp;#34; &amp;#34;os&amp;#34; &amp;#34;strings&amp;#34; &amp;#34;time&amp;#34; ) func robin() { hostsList := os.Getenv(&amp;#34;PROXY_HOST&amp;#34;) if hostsList == &amp;#34;&amp;#34; { log.Fatal(&amp;#34;&amp;#39;PROXY_HOST&amp;#39; environment variable should contain comma-separated list of hosts&amp;#34;) } // Comma-separated lists of hosts  hosts := strings.Split(hostsList, &amp;#34;,&amp;#34;) urls := make([]*url.URL, len(hosts)) for i, host := range hosts { var origin = Endpoint{ Host: host, Port: os.</description>
    </item>
    
    <item>
      <title>Cloud Functions Simple(st) HTTP Proxy</title>
      <link>https://pretired.dazwilkin.com/posts/190917/</link>
      <pubDate>Tue, 17 Sep 2019 12:41:02 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190917/</guid>
      <description>I&amp;rsquo;m investigating the use of LetsEncrypt for gRPC services. I found this straightforward post by Scott Devoid and am going to try this approach.
Before I can do that, I need to be able to publish services (make them Internet-accessible) and would like to try to continue to use GCP for free.
Some time ago, I wrote about using the excellent Microk8s on GCP. Using an f1-micro, I&amp;rsquo;m hoping (!) to stay within the Compute Engine free tier.</description>
    </item>
    
    <item>
      <title>pypi-transparency</title>
      <link>https://pretired.dazwilkin.com/posts/190907/</link>
      <pubDate>Sat, 07 Sep 2019 13:07:44 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/190907/</guid>
      <description>The goal of pypi-transparency is very similar to the underlying motivation for the Golang team&amp;rsquo;s Checksum Database (also built with Trillian).
Even though, PyPi provides hashes of the content of packages it hosts, the developer must trust that PyPi&amp;rsquo;s data is consistent. One ambition with pypi-transparency is to provide a companion, tamperproof log of PyPi package files in order to provide a double-check of these hashes.
It is important to understand what this does (and does not) provide.</description>
    </item>
    
  </channel>
</rss>