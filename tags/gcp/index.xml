<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GCP on (p)retired</title>
    <link>https://pretired.dazwilkin.com/tags/gcp/</link>
    <description>Recent content in GCP on (p)retired</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 May 2022 00:00:00 -0700</lastBuildDate><atom:link href="https://pretired.dazwilkin.com/tags/gcp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prometheus Exporters for fly.io and Vultr</title>
      <link>https://pretired.dazwilkin.com/posts/220520/</link>
      <pubDate>Fri, 20 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220520/</guid>
      <description>I&amp;rsquo;ve been on a roll building utilities this week. I developed a Service Health dashboard for my &amp;ldquo;thing&amp;rdquo;, a Prometheus Exporter for Fly.io and today, a Prometheus Exporter for Vultr. This is motivated by the fear that I will forget a deployed Cloud resource and incur a horrible bill.
I&amp;rsquo;ve no written several Prometheus Exporters for cloud platforms:
Prometheus Exporter for GCP Prometheus Exporter for Linode Prometheus Exporter for Fly.io Prometheus Exporter for Vultr Each of them monitors resource deployments and produces resource count metrics that can be scraped by Prometheus and alerted with Alertmanager.</description>
    </item>
    
    <item>
      <title>Using Google Monitoring Alerting to send Pushover notifications</title>
      <link>https://pretired.dazwilkin.com/posts/220514/</link>
      <pubDate>Sat, 14 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220514/</guid>
      <description>Table of Contents Artifacts Pushover Caveat Cloud Monitoring Webhook Cloud Functions Cloud Run Artifacts GitHub: go-gcp-pushover-notificationchannel Image: ghcr.io/dazwilkin/go-gcp-pushover-notificationchannel:220515 Pushover Logging in to your Pushover account, you will be presented with a summary|dashboard page that includes Your User Key. Copy the value of this key into a variable called PUSHOVER_USER
Create New Application|API Token
Pushover API has a Pushing Messages method. The documentation describes the format of the HTTP Request. It must be a POST using TLS (https://) to https://api.</description>
    </item>
    
    <item>
      <title>Cloud Run custom domain mappings</title>
      <link>https://pretired.dazwilkin.com/posts/220506/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220506/</guid>
      <description>I have several Cloud Run services that I want to map to a domain.
During development, I create a Google Cloud Platform (GCP) project each day into which everything is deployed. This means that, every day, the Cloud Run services have newly non-inferable (to me) URLs. I thought this would be tedious to manage because:
My DNS service isn&amp;rsquo;t programmable (I know!) Cloud Run services have non-inferable (by me) URLs i.</description>
    </item>
    
    <item>
      <title>Automating Scheduled Firestore Exports</title>
      <link>https://pretired.dazwilkin.com/posts/220503/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220503/</guid>
      <description>For my &amp;ldquo;thing&amp;rdquo;, I use Firestore to persist state. I like Firestore a lot and, having been around Google for almost (!) a decade, I much prefer it to Datastore.
Firestore has a managed export|import service and I use this to backup Firestore collections|documents.
I&amp;rsquo;d been doing backups manually (using gcloud) and decided today to take the plunge and use Cloud Scheduler for the first time. I&amp;rsquo;d been reluctant to do this until now because I&amp;rsquo;d assumed incorrectly that I&amp;rsquo;d need to write a wrapping service to invoke the export.</description>
    </item>
    
    <item>
      <title>Using Google&#39;s Public Certificate Authority with Golang autocert</title>
      <link>https://pretired.dazwilkin.com/posts/220421/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/220421/</guid>
      <description>Last year, I wrote about using Automatic Certs w/ Golang gRPC service on Compute Engine. That solution uses ACME with (the wonderful) Let&amp;rsquo;s Encrypt. Google is offering a private preview of Automate Public Certificates Lifecycle Management via RFC 8555 (ACME) and, because I&amp;rsquo;m using Google Cloud Platform extensively to build a &amp;ldquo;thing&amp;rdquo; and I think it would be useful to have a backup to Let&amp;rsquo;s Encrypt, I thought I&amp;rsquo;d give the solution a try.</description>
    </item>
    
    <item>
      <title>Infrastructure as Code</title>
      <link>https://pretired.dazwilkin.com/posts/210902/</link>
      <pubDate>Thu, 02 Sep 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210902/</guid>
      <description>Problem I&amp;rsquo;m building an application that comprises:
Kubernetes¹ Kubernetes Operator Cloud Firestore Cloud Functions Cloud Run Cloud Endpoints Stripe Firebase Authentication ¹ - I&amp;rsquo;m using Google Kubernetes Engine (GKE) but may include other managed Kubernetes offerings (e.g. Digital Ocean, Linode, Oracle). GKE clusters are manageable by gcloud but other platforms require other CLI tools. All are accessible from bash but are these supported by e.g. Terraform (see below)?
Many of the components are packaged as container images and, because I&amp;rsquo;m using GitHub to host the project&amp;rsquo;s repos (I&amp;rsquo;ll leave the monorepo discussion for another post), I&amp;rsquo;ve become inculcated and use GitHub Container Registry (GHCR) as the container repo.</description>
    </item>
    
    <item>
      <title>Cloud Firestore Triggers in Golang</title>
      <link>https://pretired.dazwilkin.com/posts/210413/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/210413/</guid>
      <description>I was pleased to discover that Google provides a non-Node.JS mechanism to subscribe to and act upon Firestore triggers, Google Cloud Firestore Triggers. I&amp;rsquo;ve nothing against Node.JS but, for the project i&amp;rsquo;m developing, everything else is written in Golang. It&amp;rsquo;s good to keep it all in one language.
I&amp;rsquo;m perplexed that Cloud Functions still (!) only supports Go 1.13 (03-Sep-2019). Even Go 1.14 (25-Feb-2020) was released pre-pandemic and we&amp;rsquo;re now running on 1.</description>
    </item>
    
    <item>
      <title>WASM Cloud Functions</title>
      <link>https://pretired.dazwilkin.com/posts/200617/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200617/</guid>
      <description>Following on from waPC &amp;amp; Protobufs and a question on Stack Overflow about Cloud Functions, I was compelled to try running WASM on Cloud Functions no JavaScript.
I wanted to reuse the WASM waPC functions that I&amp;rsquo;d written in Rust as described in the other post. Cloud Functions does not (yet!?) provide a Rust runtime and so I&amp;rsquo;m using the waPC Host for Go in this example.
It works!
PARAMS=$(printf &amp;#39;{&amp;#34;a&amp;#34;:{&amp;#34;real&amp;#34;:39,&amp;#34;imag&amp;#34;:3},&amp;#34;b&amp;#34;:{&amp;#34;real&amp;#34;:39,&amp;#34;imag&amp;#34;:3}}&amp;#39; | base64) TOKEN=$(gcloud auth print-identity-token) echo &amp;#34;{ \&amp;#34;filename\&amp;#34;:\&amp;#34;complex.</description>
    </item>
    
    <item>
      <title>Setting up a GCE Instance as an Inlets Exit Node</title>
      <link>https://pretired.dazwilkin.com/posts/200122/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 -0800</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/200122/</guid>
      <description>The prolific Alex Ellis has a new project, Inlets.
Here&amp;rsquo;s a quick tutorial using Google Compute Platform&amp;rsquo;s (GCP) Compute Engine (GCE).
NB I&amp;rsquo;m using one of Google&amp;rsquo;s &amp;ldquo;Always free&amp;rdquo; f1-micro instances but you may still pay for network *gress and storage
Assumptions I&amp;rsquo;m assuming you&amp;rsquo;ve a Google account, have used GCP and have a billing account established, i.e. the following returns at least one billing account:
gcloud beta billing accounts list If you&amp;rsquo;ve only one billing account and it&amp;rsquo;s the one you wish to use, then you can:</description>
    </item>
    
    <item>
      <title>Google Cloud Platform (GCP) Exporter</title>
      <link>https://pretired.dazwilkin.com/posts/191220/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 -0700</pubDate>
      
      <guid>https://pretired.dazwilkin.com/posts/191220/</guid>
      <description>Earlier this week I discussed a Linode Prometheus Exporter.
I added metrics for Digital Ocean&amp;rsquo;s Managed Kubernetes service to @metalmatze&amp;rsquo;s Digital Ocean Exporter.
This left, metrics for Google Cloud Platform (GCP) which has, for many years, been my primary cloud platform. So, today I wrote Prometheus Exporter for Google Cloud Platform.
All 3 of these exporters follow the template laid down by @metalmatze and, because each of these services has a well-written Golang SDK, it&amp;rsquo;s straightforward to implement an exporter for each of them.</description>
    </item>
    
  </channel>
</rss>
